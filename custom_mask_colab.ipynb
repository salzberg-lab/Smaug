{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"custom_mask_colab.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"03irV-C_6jpZ","colab_type":"code","outputId":"2f846dbf-4743-4d31-f335-2cc9089da00a","executionInfo":{"status":"ok","timestamp":1571937140811,"user_tz":240,"elapsed":8681,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":641}},"source":["!pip install transformers"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/f9/51824e40f0a23a49eab4fcaa45c1c797cbf9761adedd0b558dab7c958b34/transformers-2.1.1-py3-none-any.whl (311kB)\n","\u001b[K     |████████████████████████████████| 317kB 2.7MB/s \n","\u001b[?25hCollecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 33.0MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.3)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n","\u001b[K     |████████████████████████████████| 860kB 35.4MB/s \n","\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.9.253)\n","Collecting regex\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/60/d9782c56ceefa76033a00e1f84cd8c586c75e6e7fea2cd45ee8b46a386c5/regex-2019.08.19-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n","\u001b[K     |████████████████████████████████| 645kB 48.1MB/s \n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.9.11)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.0)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n","Requirement already satisfied: botocore<1.13.0,>=1.12.253 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.12.253)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.253->boto3->transformers) (2.6.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.253->boto3->transformers) (0.15.2)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=d39efb3052312c9ea1d971b5482e226e62c9e96424954a64b0d319cd574112cd\n","  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, sacremoses, regex, transformers\n","Successfully installed regex-2019.8.19 sacremoses-0.0.35 sentencepiece-0.1.83 transformers-2.1.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MTLDde1m6k_O","colab_type":"code","outputId":"826046fb-788a-442b-eca7-426e479ba7b3","executionInfo":{"status":"ok","timestamp":1571937178497,"user_tz":240,"elapsed":45162,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":123}},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X3i73FlB55Xt","colab_type":"code","colab":{}},"source":["import os\n","import sys\n","import pickle\n","import torch\n","import numpy as np\n","import torch.optim as optim\n","from transformers import BertConfig, BertModel, BertForMaskedLM\n","\n","from IPython.display import clear_output\n","\n","\n","# import matplotlib.pyplot as plt\n","# from transformers import *"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kBbEF2Uc6lK5","colab_type":"code","outputId":"4f7486f8-6f17-4820-a070-0c37e0ff87fe","executionInfo":{"status":"ok","timestamp":1571937196736,"user_tz":240,"elapsed":4143,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["d = \"drive/My Drive/Colab Notebooks/smaug/data\"\n","p = os.path.join(d, \"CDS_singlestrain_threeprime.pkl\")\n","print(os.listdir(d))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['CDS_singlestrain_threeprime.pkl']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cA49xxRjaakk","colab_type":"code","colab":{}},"source":["with open(p, 'rb') as f:\n","  CDS = pickle.load(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XXjv4EukaaiC","colab_type":"code","outputId":"18ae2aeb-a885-4e9d-8f41-ba185ad605e9","executionInfo":{"status":"ok","timestamp":1571937247933,"user_tz":240,"elapsed":53506,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["print(type(CDS))\n","print(len(CDS))\n","print(CDS[100])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<class 'list'>\n","9304394\n","HVSLLSVHAAVAVWRKKRQMYIDQYCVRGTKLTNAEKFVFTMYATVVGIKEDLMRVDASDINVSLIEQRRLNRIVDRRTMKNGDPSILIFDNAFIRELTVSDKSPYSRIWDENMRKLTEVSKNQAHLQCTFVMVLSFLLIAKM\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KVf-Zgp255X6","colab_type":"code","outputId":"d40fd91a-4940-476f-d9a0-7d4dd57a0e51","executionInfo":{"status":"ok","timestamp":1571937252967,"user_tz":240,"elapsed":52922,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["lengths = [len(s) for s in CDS]\n","meanlen = np.mean(lengths)\n","medlen = np.median(lengths)\n","minlen = np.min(lengths)\n","maxlen = np.max(lengths)\n","print(meanlen, medlen, minlen, maxlen)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["345.9973719943502 302.0 11 39686\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EmIQPDvZ55X9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YMj7-AzZ55YA","colab_type":"code","colab":{}},"source":["# import logging\n","# logging.basicConfig(level=logging.INFO)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dvEYlPOb55YD","colab_type":"code","colab":{}},"source":["# # custom parameters for BERT model\n","# vocab_size = 12 # Vocabulary size of inputs_ids in BertModel. default=30522\n","# hidden_size = 768 # Size of the encoder layers and the pooler layer, default=768\n","# num_hidden_layers = 12 # Number of hidden layers in the Transformer encoder. default=12\n","# num_attention_heads = 12 # Number of attention heads for each attention layer in the Transformer encoder, default=12\n","# intermediate_size = 3072 # The size of the “intermediate” (i.e., feed-forward) layer in the Transformer encoder. default=3072\n","# hidden_act = \"gelu\" # The non-linear activation function (function or string) in the encoder and pooler. If string, “gelu”, “relu”, “swish” and “gelu_new” are supported. default=\"gelu\"\n","# hidden_dropout_prob = 0.1 # The dropout probabilitiy for all fully connected layers in the embeddings, encoder, and pooler. default=0.1\n","# attention_probs_dropout_prob = 0.1 # The dropout ratio for the attention probabilities. default=0.1\n","# max_position_embeddings = 512 # The maximum sequence length that this model might ever be used with. Typically set this to something large just in case (e.g., 512 or 1024 or 2048). default=512\n","# type_vocab_size = 2 # 1 # The vocabulary size of the token_type_ids passed into BertModel. default=2\n","# initializer_range = 0.02 # The sttdev of the truncated_normal_initializer for initializing all weight matrices. default=0.02\n","# layer_norm_eps = 1e-12 # The epsilon used by LayerNorm. default=1e-12\n","\n","\n","# config = BertConfig(vocab_size_or_config_json_file=vocab_size,\n","#                     hidden_size=hidden_size,\n","#                     num_hidden_layers=num_hidden_layers,\n","#                     num_attention_heads=num_attention_heads,\n","#                     intermediate_size=intermediate_size,\n","#                     hidden_act=hidden_act,\n","#                     hidden_dropout_prob=hidden_dropout_prob,\n","#                     attention_probs_dropout_prob=attention_probs_dropout_prob,\n","#                     max_position_embeddings=max_position_embeddings,\n","#                     type_vocab_size=type_vocab_size,\n","#                     initializer_range=initializer_range,\n","#                     layer_norm_eps=layer_norm_eps)\n","\n","# model = BertForMaskedLM(config)\n","\n","# print(model)\n","# model.to('cuda')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8Ra4nFr55YF","colab_type":"code","outputId":"c97e7427-b16a-45c4-ce67-5f160cad5096","executionInfo":{"status":"ok","timestamp":1571943218930,"user_tz":240,"elapsed":498,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# custom parameters for BERT model\n","vocab_size = 22 # Vocabulary size of inputs_ids in BertModel. default=30522\n","hidden_size = 40 # Size of the encoder layers and the pooler layer, default=768\n","num_hidden_layers = 2 # Number of hidden layers in the Transformer encoder. default=12\n","num_attention_heads = 2 # Number of attention heads for each attention layer in the Transformer encoder, default=12\n","intermediate_size = hidden_size*4 # The size of the “intermediate” (i.e., feed-forward) layer in the Transformer encoder. default=3072\n","hidden_act = \"gelu\" # The non-linear activation function (function or string) in the encoder and pooler. If string, “gelu”, “relu”, “swish” and “gelu_new” are supported. default=\"gelu\"\n","hidden_dropout_prob = 0.1 # The dropout probabilitiy for all fully connected layers in the embeddings, encoder, and pooler. default=0.1\n","attention_probs_dropout_prob = 0.1 # The dropout ratio for the attention probabilities. default=0.1\n","max_position_embeddings = 50 # The maximum sequence length that this model might ever be used with. Typically set this to something large just in case (e.g., 512 or 1024 or 2048). default=512\n","type_vocab_size = 1 # 1 # The vocabulary size of the token_type_ids passed into BertModel. default=2\n","initializer_range = 0.02 # The sttdev of the truncated_normal_initializer for initializing all weight matrices. default=0.02\n","layer_norm_eps = 1e-12 # The epsilon used by LayerNorm. default=1e-12\n","\n","\n","config = BertConfig(vocab_size_or_config_json_file=vocab_size,\n","                    hidden_size=hidden_size,\n","                    num_hidden_layers=num_hidden_layers,\n","                    num_attention_heads=num_attention_heads,\n","                    intermediate_size=intermediate_size,\n","                    hidden_act=hidden_act,\n","                    hidden_dropout_prob=hidden_dropout_prob,\n","                    attention_probs_dropout_prob=attention_probs_dropout_prob,\n","                    max_position_embeddings=max_position_embeddings,\n","                    type_vocab_size=type_vocab_size,\n","                    initializer_range=initializer_range,\n","                    layer_norm_eps=layer_norm_eps)\n","\n","model = BertForMaskedLM(config)\n","\n","print(model)\n","model.to('cuda')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["BertForMaskedLM(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(22, 40, padding_idx=0)\n","      (position_embeddings): Embedding(50, 40)\n","      (token_type_embeddings): Embedding(1, 40)\n","      (LayerNorm): LayerNorm((40,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=40, out_features=40, bias=True)\n","              (key): Linear(in_features=40, out_features=40, bias=True)\n","              (value): Linear(in_features=40, out_features=40, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=40, out_features=40, bias=True)\n","              (LayerNorm): LayerNorm((40,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=40, out_features=160, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=160, out_features=40, bias=True)\n","            (LayerNorm): LayerNorm((40,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=40, out_features=40, bias=True)\n","              (key): Linear(in_features=40, out_features=40, bias=True)\n","              (value): Linear(in_features=40, out_features=40, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=40, out_features=40, bias=True)\n","              (LayerNorm): LayerNorm((40,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=40, out_features=160, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=160, out_features=40, bias=True)\n","            (LayerNorm): LayerNorm((40,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=40, out_features=40, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (cls): BertOnlyMLMHead(\n","    (predictions): BertLMPredictionHead(\n","      (transform): BertPredictionHeadTransform(\n","        (dense): Linear(in_features=40, out_features=40, bias=True)\n","        (LayerNorm): LayerNorm((40,), eps=1e-12, elementwise_affine=True)\n","      )\n","      (decoder): Linear(in_features=40, out_features=22, bias=False)\n","    )\n","  )\n",")\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["BertForMaskedLM(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(22, 40, padding_idx=0)\n","      (position_embeddings): Embedding(50, 40)\n","      (token_type_embeddings): Embedding(1, 40)\n","      (LayerNorm): LayerNorm((40,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=40, out_features=40, bias=True)\n","              (key): Linear(in_features=40, out_features=40, bias=True)\n","              (value): Linear(in_features=40, out_features=40, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=40, out_features=40, bias=True)\n","              (LayerNorm): LayerNorm((40,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=40, out_features=160, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=160, out_features=40, bias=True)\n","            (LayerNorm): LayerNorm((40,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=40, out_features=40, bias=True)\n","              (key): Linear(in_features=40, out_features=40, bias=True)\n","              (value): Linear(in_features=40, out_features=40, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=40, out_features=40, bias=True)\n","              (LayerNorm): LayerNorm((40,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=40, out_features=160, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=160, out_features=40, bias=True)\n","            (LayerNorm): LayerNorm((40,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=40, out_features=40, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (cls): BertOnlyMLMHead(\n","    (predictions): BertLMPredictionHead(\n","      (transform): BertPredictionHeadTransform(\n","        (dense): Linear(in_features=40, out_features=40, bias=True)\n","        (LayerNorm): LayerNorm((40,), eps=1e-12, elementwise_affine=True)\n","      )\n","      (decoder): Linear(in_features=40, out_features=22, bias=False)\n","    )\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":127}]},{"cell_type":"code","metadata":{"id":"rf0FLgnQ55YI","colab_type":"code","outputId":"57291769-1713-419e-946b-cca160116dc3","executionInfo":{"status":"ok","timestamp":1571943220562,"user_tz":240,"elapsed":1384,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":155}},"source":["# encode data as GPU tensors\n","max_aa_seq_length = max_position_embeddings\n","\n","\n","def tokenize_aa_seq_murphy10(aa_seq):\n","    table = {\"L\":1,\n","             \"V\":1,\n","             \"I\":1,\n","             \"M\":1,\n","             \"C\":2,\n","             \"A\":3,\n","             \"G\":4,\n","             \"S\":5,\n","             \"T\":5,\n","             \"P\":6,\n","             \"F\":7,\n","             \"Y\":7,\n","             \"W\":7,\n","             \"E\":8,\n","             \"D\":8,\n","             \"N\":8,\n","             \"Q\":8,\n","             \"K\":9,\n","             \"R\":9,\n","             \"H\":10,\n","             \"X\":0, # get rid of those\n","             \"B\":0,\n","             \"*\":0}\n","    tokenized = [table[aa] for aa in aa_seq]\n","    return tokenized\n","\n","def tokenize_aa_seq(aa_seq):\n","    table = {\"L\":1,\n","             \"V\":2,\n","             \"I\":3,\n","             \"M\":4,\n","             \"C\":5,\n","             \"A\":6,\n","             \"G\":7,\n","             \"S\":8,\n","             \"T\":9,\n","             \"P\":10,\n","             \"F\":11,\n","             \"Y\":12,\n","             \"W\":13,\n","             \"E\":14,\n","             \"D\":15,\n","             \"N\":16,\n","             \"Q\":17,\n","             \"K\":18,\n","             \"R\":19,\n","             \"H\":20,\n","             \"X\":0, # get rid of those\n","             \"B\":0,\n","             \"*\":0}\n","    tokenized = [table[aa] for aa in aa_seq]\n","    return tokenized\n","\n","# tokens = [tokenize_aa_seq_murphy10(seq) for seq in CDS[:1000]] ######################################\n","tokens = [tokenize_aa_seq(seq) for seq in CDS[:1000]] ######################################\n","\n","tokens_tensor = torch.zeros(len(tokens), max_aa_seq_length, dtype=torch.long)\n","for i in range(len(tokens)):\n","    l = len(tokens[i]) # scuff way to ensure fit in tensor, TODO build correctly sized data set and split into train test\n","    if l > max_aa_seq_length:\n","        l = max_aa_seq_length\n","    for j in range(l):\n","        tokens_tensor[i][j] += tokens[i][j]\n","\n","tokens_tensor = tokens_tensor.to('cuda')\n","\n","print(tokens_tensor)\n","print(tokens_tensor.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[18,  1,  4,  ...,  9,  6,  7],\n","        [ 6, 17,  6,  ...,  4,  2, 11],\n","        [15, 19,  1,  ..., 18,  8,  9],\n","        ...,\n","        [ 1, 15, 14,  ...,  2,  8, 15],\n","        [18,  1, 18,  ...,  1, 17,  5],\n","        [ 3, 19,  6,  ...,  2,  6, 13]], device='cuda:0')\n","torch.Size([1000, 50])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wkyp8xJa55YK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zlHdsHkb55YM","colab_type":"code","outputId":"cd90299c-1f10-48c9-86e5-83f3e23c4b0f","executionInfo":{"status":"ok","timestamp":1571943223745,"user_tz":240,"elapsed":496,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["dtrain = tokens_tensor[:int(0.8*len(tokens_tensor))] #TODO do an actual random selection on better data\n","dvalid = tokens_tensor[int(0.8*len(tokens_tensor)):]\n","print(len(dtrain))\n","print(len(dvalid))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["800\n","200\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vzh6lkJpcfTW","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fXThUjamEcFX","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KUuZzFiD55YQ","colab_type":"code","colab":{}},"source":["# optimizer = optim.SGD(model.parameters(), lr=0.0001)#, momentum=args.momentum)\n","optimizer = optim.AdamW(model.parameters())\n","# optimizer = optim.Adam(model.parameters())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fUCw7GIA9vDL","colab_type":"code","outputId":"43be424f-11ca-4624-e93d-3163fd097078","executionInfo":{"status":"error","timestamp":1571942298985,"user_tz":240,"elapsed":224,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":676}},"source":["# train model with single aa masked at a time ##### batch\n","model.train()\n","\n","batch_size = 2**12\n","\n","\n","loss_mask = (torch.zeros(batch_size, max_position_embeddings)-1).long().to('cuda')\n","\n","np.random.seed(2019)\n","np.random.seed(10)\n","\n","model.zero_grad()\n","optimizer.zero_grad()\n","\n","for i in range(1000):\n","    select_idx = np.random.randint(0, len(dtrain), batch_size)\n","#     input_ids = dtrain[select_idx].unsqueeze(0)\n","    input_ids_correct = dtrain[select_idx]\n","    input_ids = input_ids_correct.clone()\n","\n","    for j in range(max_position_embeddings):\n","        tempval = torch.zeros(batch_size).long()\n","\n","        for k in range(batch_size):\n","            tempval[k] = input_ids[k, j].item()\n","        \n","        optimizer.zero_grad()\n","        model.zero_grad()\n","\n","        loss_mask[:, j] = tempval # calculate loss based only on masked amino acid\n","      \n","        input_ids[:, j] = vocab_size-1 # mask label is the highest vocab number, never present in data\n","\n","        outputs = model(input_ids, masked_lm_labels=loss_mask) #TODO mask padding 0's for attention\n","#         outputs = model(input_ids, masked_lm_labels=input_ids_correct) #TODO mask padding 0's for attention\n","#         print(outputs)\n","\n","        loss, prediction_scores = outputs[:2]\n","#         loss, prediction_scores = outputs\n","\n","        \n","        # for k in range(batch_size):\n","        clear_output(wait=True)\n","        for k in range(3):\n","            print(i, \"\\t\", torch.argmax(prediction_scores[k,j]).item(), '\\t', loss_mask[k,j].item(), \"\\t\", loss.item())\n","            print(prediction_scores[k,j])\n","        print()\n","        \n","        loss.backward()\n","        optimizer.step()\n","\n","        for k in range(batch_size):\n","            input_ids[k, j] = tempval[k] # set masked value back to original value\n","            loss_mask[k, j] = -1\n","\n","#         else:\n","#             break # stop training at end of protein sequence\n","\n","#     break"],"execution_count":0,"outputs":[{"output_type":"stream","text":["3 1 \t 12 \t 2.858600616455078\n","tensor([-2.4624,  1.2467,  0.7528,  0.8444, -0.2993, -1.5819,  1.0521,  0.8769,\n","         0.6866,  0.6325,  0.3416,  0.5186,  0.0666, -0.6995,  0.7221,  0.4601,\n","         0.2751,  0.0170,  1.0462,  0.5948, -0.3550, -2.3411], device='cuda:0',\n","       grad_fn=<SelectBackward>)\n","3 1 \t 12 \t 2.858600616455078\n","tensor([-2.6119,  1.2514,  0.8257,  0.8974, -0.2989, -1.6216,  1.0534,  0.8919,\n","         0.6413,  0.6600,  0.4567,  0.5320,  0.1353, -0.7860,  0.7546,  0.4764,\n","         0.2847,  0.1360,  1.1082,  0.5964, -0.3567, -2.3738], device='cuda:0',\n","       grad_fn=<SelectBackward>)\n","3 1 \t 3 \t 2.858600616455078\n","tensor([-2.3881,  1.1734,  0.7367,  0.8986, -0.2904, -1.5358,  1.0004,  0.7635,\n","         0.5814,  0.5518,  0.4343,  0.5683,  0.1160, -0.7785,  0.7463,  0.4270,\n","         0.2483,  0.0958,  1.0449,  0.5569, -0.2832, -2.2015], device='cuda:0',\n","       grad_fn=<SelectBackward>)\n","\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-110-f00c75678f40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"ZkwhQJDvTld6","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FqE7GOhKTVf_","colab_type":"code","outputId":"f7e586b8-7b10-48bb-ce82-7b55ec52cae3","executionInfo":{"status":"error","timestamp":1571943463020,"user_tz":240,"elapsed":560,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":165}},"source":["# TRIVIAL TEST, TRAIN A MODEL ON SAME DATA REPEATEDLY\n","model.train()\n","\n","batch_size = 2**10\n","\n","\n","loss_mask = (torch.zeros(batch_size, max_position_embeddings)-1).long().to('cuda')\n","\n","np.random.seed(2019)\n","for i in range(1000):\n","#     select_idx = np.random.randint(0, len(dtrain), batch_size)\n","    select_idx = np.random.randint(0, 1, batch_size)\n","\n","#     input_ids = dtrain[select_idx].unsqueeze(0)\n","    input_ids_correct = dtrain[select_idx]\n","    input_ids = input_ids_correct.clone()\n","\n","    for j in range(max_position_embeddings):\n","        tempval = torch.zeros(batch_size).long()\n","\n","        for k in range(batch_size):\n","            tempval[k] = input_ids[k, j].item()\n","        \n","        optimizer.zero_grad()\n","\n","        loss_mask[:, j] = tempval # calculate loss based only on masked amino acid\n","      \n","        input_ids[:, j] = vocab_size-1 # mask label is the highest vocab number, never present in data\n","\n","#         outputs = model(input_ids, masked_lm_labels=input_ids_correct) #TODO mask padding 0's for attention\n","        outputs = model(input_ids, masked_lm_labels=loss_mask) #TODO mask padding 0's for attention\n","        print(loss_mask.shape)\n","#         print(input_ids)\n","        sys.exit()\n","\n","        loss, prediction_scores = outputs[:2]\n","#         loss, prediction_scores = outputs\n","\n","        clear_output(wait=True)\n","        for k in range(3):\n","            print(i, torch.argmax(prediction_scores[k+1,j]).item(), loss_mask[k,j].item(), \"\\t\", loss.item())\n","        \n","        print()\n","        \n","        loss.backward()\n","        optimizer.step()\n","\n","        for k in range(batch_size):\n","            input_ids[k, j] = tempval[k] # set masked value back to original value\n","            loss_mask[k, j] = -1\n","\n","#         else:\n","#             break # stop training at end of protein sequence\n","\n","#     break"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([1024, 50])\n"],"name":"stdout"},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\n"]},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"mrpb6Q9_R-gH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PKPz_z3Z55YU","colab_type":"code","outputId":"3bfb0be2-98dd-4402-b93c-45831017e1d8","executionInfo":{"status":"ok","timestamp":1571940657382,"user_tz":240,"elapsed":26696,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# evaluate the model using softmax proportion of correct label\n","model.eval()\n","\n","np.random.seed(424242)\n","\n","maxsum = 0\n","softsum = 0\n","n_correct = 0\n","n_total = 0\n","for i in range(100):\n","    select_idx = np.random.randint(0,len(dvalid),1)[0]    \n","    input_ids = dvalid[select_idx].unsqueeze(0)\n","    # print(input_ids)\n","    \n","    for j in range(max_position_embeddings):\n","        tempval = 0\n","        tempval += input_ids[0, j].item()\n","        if tempval != 0:\n","            input_ids[0, j] = vocab_size-1 # mask label is the highest vocab number, never present in data\n","            logits = model(input_ids)[0][0,j]\n","            soft = torch.exp(logits)\n","            softproportion = (soft[tempval]/torch.sum(soft)).item() #######bug tempval not j\n","            softsum += softproportion\n","            maxsum += 1\n","\n","            pred = torch.argmax(logits).item()\n","            actual = tempval\n","            n_correct += pred==actual\n","            n_total +=1\n","            \n","            input_ids[0,j] = tempval # set masked value back to original value\n","\n","correctness = softsum/maxsum\n","print(correctness)\n","\n","correctness_p = n_correct/n_total\n","print(correctness_p)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.06227649919032701\n","0.0844\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u4fKWD8CvGkt","colab_type":"code","outputId":"f7328c42-e75c-4976-da84-d816799e4823","executionInfo":{"status":"error","timestamp":1571940237299,"user_tz":240,"elapsed":12063,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":379}},"source":["# evaluate the model using softmax proportion of correct label, ON NOISE\n","model.eval()\n","\n","np.random.seed(424242)\n","\n","maxsum = 0\n","softsum = 0\n","n_correct = 0\n","n_total = 0\n","for i in range(100):\n","#     select_idx = np.random.randint(0,len(dvalid),1)[0]    \n","#     input_ids = dvalid[select_idx].unsqueeze(0)\n","    noise = np.random.randint(1, 20, max_position_embeddings).reshape(1,-1)\n","    input_ids = torch.from_numpy(noise).to('cuda')\n","#     print(input_ids)\n","    \n","    for j in range(max_position_embeddings):\n","        tempval = 0\n","        tempval += input_ids[0, j].item()\n","        if tempval != 0:\n","            input_ids[0, j] = vocab_size-1 # mask label is the highest vocab number, never present in data\n","            logits = model(input_ids)[0][0,j]\n","            soft = torch.exp(logits)\n","            softproportion = (soft[tempval]/torch.sum(soft)).item()\n","            softsum += softproportion\n","            maxsum += 1\n","#             print(softproportion)\n","\n","            pred = torch.argmax(logits).item()\n","            actual = tempval\n","            n_correct += pred==actual\n","            n_total +=1\n","            \n","            input_ids[0,j] = tempval # set masked value back to original value\n","\n","correctness = softsum/maxsum\n","print(correctness)\n","\n","correctness_p = n_correct/n_total\n","print(correctness_p)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-95-63667d3968d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtempval\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;31m# mask label is the highest vocab number, never present in data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0msoft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0msoftproportion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msoft\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtempval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, masked_lm_labels)\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m         \u001b[0mprediction_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprediction_scores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Add hidden states and attention if they are here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sequence_output)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0mprediction_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprediction_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mgelu\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mAlso\u001b[0m \u001b[0msee\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0marxiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1606.08415\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \"\"\"\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgelu_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"WVEg6OMvZua6","colab_type":"code","outputId":"baae6468-7eb0-4936-f60b-279e789563ed","executionInfo":{"status":"ok","timestamp":1571940243407,"user_tz":240,"elapsed":1661,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# evaluate using model that just predicts most common amino acid\n","model.eval()\n","\n","np.random.seed(424242)\n","\n","\n","maxsum = 0\n","softsum = 0\n","n_correct = 0\n","n_total = 0\n","for i in range(100):\n","    select_idx = np.random.randint(0,len(dvalid),1)[0]    \n","    input_ids = dvalid[select_idx].unsqueeze(0)\n","    \n","    for j in range(max_position_embeddings):\n","        tempval = 0\n","        tempval += input_ids[0, j].item()\n","        if tempval != 0:\n","            input_ids[0, j] = vocab_size-1 # mask label is the highest vocab number, never present in data\n","            soft = torch.zeros(vocab_size)\n","            soft[1] += 1\n","            softproportion = (soft[tempval]/torch.sum(soft)).item()\n","            softsum += softproportion\n","            maxsum += 1\n","\n","            pred = torch.argmax(soft).item()\n","\n","            actual = tempval\n","            n_correct += pred==actual\n","            n_total += 1\n","            \n","            input_ids[0,j] = tempval # set masked value back to original value\n","\n","correctness = softsum/maxsum\n","print(correctness)\n","\n","correctness_p = n_correct/n_total\n","print(correctness_p)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.0878\n","0.0878\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hnHLZnJL4Lzy","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z2RpZdto55Ya","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NRKlpDWC55Yb","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"19Smkiji55Yd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BtmrJyUJ55Ye","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QwRPG3cX55Yg","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oThB3Osi55Yi","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"laiAuExQ55Yn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r7xT6bIj55Yo","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-0tWGotR55Yy","colab_type":"code","colab":{}},"source":["# train model\n","batch_size = 1\n","\n","optimizer = optim.SGD(model.parameters(), lr=0.01)#, momentum=args.momentum)\n","# optimizer = optim.AdamW(model.parameters())\n","_max_select = len(dtrain)\n","\n","\n","# single step to non-zero weights\n","optimizer.zero_grad()\n","select_idx = np.random.randint(0, _max_select, batch_size)\n","outputs = model(dtrain[select_idx], masked_lm_labels=dtrain[select_idx])\n","loss, prediction_scores = outputs[:2]\n","loss.backward()\n","optimizer.step()\n","\n","# # evaluate before training\n","# acc_train = evaluate(model, dtrain)\n","# acc_valid = evaluate(model, dvalid)\n","# print(acc_train)\n","# print(acc_valid)\n","\n","\n","# train\n","model.train()\n","np.random.seed(2019)\n","for i in range(100):\n","    optimizer.zero_grad()\n","    select_idx = np.random.randint(0, _max_select, batch_size)\n","    input_ids = tokens_tensor[select_idx]\n","    outputs = model(input_ids, masked_lm_labels=input_ids)\n","    loss, prediction_scores = outputs[:2]\n","    print(i, loss.item())\n","    loss.backward()\n","    optimizer.step()\n","    \n","#     loss.backward(retain_graph=True)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EH1AQEIR55Y0","colab_type":"code","colab":{}},"source":["# after training\n","acc_train = evaluate(model, dtrain)\n","acc_valid = evaluate(model, dvalid)\n","print(acc_train)\n","print(acc_valid)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cFBbjL0U55Y2","colab_type":"code","colab":{}},"source":["model.eval()\n","outputs = model(dvalid[0].unsqueeze(0), masked_lm_labels=dvalid[0].unsqueeze(0))\n","loss, prediction_scores = outputs[:2]\n","\n","predicted_index = torch.argmax(prediction_scores, dim=2)\n","print(predicted_index)\n","print(dvalid[0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5-S5jD8b55Y3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MrUL2vPe55Y5","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UM8u0ry555Y6","colab_type":"code","colab":{}},"source":["\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tJJWFg6E55Y8","colab_type":"code","colab":{}},"source":["# debug\n","model.train()\n","optimizer = optim.SGD(model.parameters(), lr=0.01)#, momentum=args.momentum)\n","for i in range(10):\n","    optimizer.zero_grad()\n","#     select_idx = 1\n","#     input_ids = tokens_tensor[select_idx].unsqueeze(0)\n","#     input_ids = tokens_tensor[0:3]\n","    input_ids = dtrain[0].unsqueeze(0)\n","\n","    outputs = model(input_ids, masked_lm_labels=input_ids)\n","    loss, prediction_scores = outputs[:2]\n","    print(i, loss.item())\n","    loss.backward()\n","    optimizer.step()\n","    \n","#     loss.backward(retain_graph=True)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KRXZhMQl55Y-","colab_type":"code","colab":{}},"source":["model.eval()\n","select_idx = 5\n","input_ids = tokens_tensor[select_idx].unsqueeze(0)\n","outputs = model(input_ids, masked_lm_labels=input_ids)\n","loss, prediction_scores = outputs[:2]\n","\n","predicted_index = torch.argmax(prediction_scores, dim=2)\n","a = evaluate(model, tokens_tensor[select_idx].unsqueeze(0))\n","print(a)\n","# print(predicted_index.shape)\n","print(predicted_index)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rPNcl53N55ZA","colab_type":"code","colab":{}},"source":["# evaluate on random data to ensure accuracy metric works\n","model.eval()\n","\n","np.random.seed(2019)\n","noise = np.random.randint(1, 10, 512).reshape(1,-1)\n","input_ids = torch.from_numpy(noise).to('cuda')\n","\n","outputs = model(input_ids, masked_lm_labels=input_ids)\n","loss, prediction_scores = outputs[:2]\n","\n","predicted_index = torch.argmax(prediction_scores, dim=2)\n","a = evaluate(model, tokens_tensor[select_idx].unsqueeze(0))\n","print(a)\n","# print(predicted_index.shape)\n","print(input_ids)\n","print(predicted_index)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Vnu2wrN55ZC","colab_type":"code","colab":{}},"source":["# fix forward mask\n","model.eval()\n","\n","np.random.seed(2019)\n","noise = np.random.randint(1, 10, 512).reshape(1,-1)\n","input_ids = torch.from_numpy(noise).to('cuda')\n","input_ids[0,0] = -inf\n","\n","attention_mask = torch.from_numpy(np.ones(512).reshape(1,-1)).float().to('cuda')\n","attention_mask[0,0] = 0\n","# print(attention_mask)\n","\n","token_type_ids = torch.from_numpy(np.zeros(512).reshape(1,-1)).long().to('cuda')\n","\n","outputs = model(input_ids, masked_lm_labels=input_ids)\n","loss, prediction_scores = outputs[:2]\n","\n","predicted_index = torch.argmax(prediction_scores, dim=2)\n","a = evaluate(model, tokens_tensor[select_idx].unsqueeze(0))\n","print(a)\n","# print(predicted_index.shape)\n","print(input_ids)\n","print(predicted_index)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pJau2_9b55ZE","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XT2JkPMN55ZG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6j2KIu7f55ZI","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7Z0_Jgm55ZK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ASXO5gOa55ZN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PSU4rrdO55ZP","colab_type":"code","colab":{}},"source":["del model\n","torch.cuda.empty_cache()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aI-t2Rs555ZU","colab_type":"code","colab":{}},"source":["# train model\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","def train_epoch(epoch, args, model, device, data_loader, optimizer):\n","    model.train()  # set to training mode, disappointingly does not actually train the model \n","    pid = os.getpid()\n","    for batch_idx, (data, target) in enumerate(data_loader):\n","        optimizer.zero_grad()\n","        output = model(data.to(device))\n","        loss = F.nll_loss(output, target.to(device))\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % args.log_interval == 0:\n","            print('{}\\tTrain Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                pid, epoch, batch_idx * len(data), len(data_loader.dataset),\n","                100. * batch_idx / len(data_loader), loss.item()))\n","            \n","optimizer = optim.SGD(model.parameters(), lr=0.01)#, momentum=args.momentum)\n","optimizer.zero_grad()\n","# output = model(tokens_tensor)\n","# loss = F.nll_loss(output, target.to('cuda'))\n","print([x for x in model.parameters()])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PoBBBQeO55ZV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iiY2TVZI55ZW","colab_type":"code","colab":{}},"source":["from transformers import BertTokenizer, BertModel, BertForMaskedLM\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","# model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n","model = BertForMaskedLM(config)\n","\n","input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\")).unsqueeze(0)  # Batch size 1\n","outputs = model(input_ids, masked_lm_labels=input_ids)\n","loss, prediction_scores = outputs[:2]\n","print(loss)\n","print(prediction_scores)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gxSiqrMs55ZY","colab_type":"code","colab":{}},"source":["print(input_ids.shape)\n","print(tokens_tensor[0].unsqueeze(0).shape)\n","print(tokens_tensor[0:2].shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DYID7shz55ZZ","colab_type":"code","colab":{}},"source":["from transformers import BertTokenizer, BertModel, BertForMaskedLM\n","\n","# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","# model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n","model = BertForMaskedLM(config)\n","model.to('cuda')\n","\n","# input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\")).unsqueeze(0)  # Batch size 1\n","# input_ids = tokens_tensor[0].unsqueeze(0)\n","input_ids = tokens_tensor[0:2]\n","\n","outputs = model(input_ids, masked_lm_labels=input_ids)\n","loss, prediction_scores = outputs[:2]\n","print(loss)\n","print(prediction_scores.shape)\n","\n","for i in range(2):\n","    input_ids = tokens_tensor[0:2]\n","    outputs = model(input_ids, masked_lm_labels=input_ids)\n","    loss, prediction_scores = outputs[:2]\n","    loss.backward()\n","    print(loss)\n","    print(prediction_scores.shape)\n","#     loss.backward(retain_graph=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XfFqO-6r55Zd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tGFpnqCO55Zh","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EXV_Oiij55Zi","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qpPPk-sf55Zl","colab_type":"code","colab":{}},"source":["import torch\n","from transformers import BertTokenizer, BertModel, BertForMaskedLM\n","\n","# OPTIONAL: if you want to have more information on what's happening under the hood, activate the logger as follows\n","# import logging\n","# logging.basicConfig(level=logging.INFO)\n","# logging.basicConfig(level=logging.NONE)\n","\n","\n","# Load pre-trained model tokenizer (vocabulary)\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# Tokenize input\n","text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n","tokenized_text = tokenizer.tokenize(text)\n","\n","# Mask a token that we will try to predict back with `BertForMaskedLM`\n","# masked_index = 8\n","# tokenized_text[masked_index] = '[MASK]'\n","\n","# Convert token to vocabulary indices\n","indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n","print(indexed_tokens)\n","# Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n","segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n","\n","# Convert inputs to PyTorch tensors\n","tokens_tensor = torch.tensor([indexed_tokens])\n","segments_tensors = torch.tensor([segments_ids])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"evUYO0la55Zn","colab_type":"code","colab":{}},"source":["# Load pre-trained model (weights)\n","model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n","model.eval()\n","\n","# If you have a GPU, put everything on cuda\n","tokens_tensor = tokens_tensor.to('cuda')\n","# segments_tensors = segments_tensors.to('cuda')\n","model.to('cuda')\n","\n","# Predict all tokens\n","with torch.no_grad():\n","#     outputs = model(tokens_tensor, token_type_ids=segments_tensors)\n","    outputs = model(tokens_tensor)\n","\n","    predictions = outputs[0]\n","\n","# confirm we were able to predict 'henson'\n","predicted_index = torch.argmax(predictions[0, masked_index]).item()\n","predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n","print(predicted_token)\n","\n","predicted_index = torch.argmax(predictions[0, 11]).item()\n","predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n","print(predicted_token)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PX9CA45w55Zq","colab_type":"code","colab":{}},"source":["for i in range(len(indexed_tokens)):\n","    predicted_index = torch.argmax(predictions[0, i]).item()\n","    predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n","    print(predicted_token)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MQ04k5P255Zr","colab_type":"code","colab":{}},"source":["predicted_token = tokenizer.convert_ids_to_tokens([103])[0]\n","print(predicted_token)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tThRe7ba55Zt","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gz4USnvY55Zv","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wz46wnbx55Zw","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KrqNGCF_55Zx","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tUsU5Ge655Zz","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dDVX4TcF55Z0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5L_l4eMA55Z1","colab_type":"code","colab":{}},"source":["import logging\n","logging.basicConfig(level=logging.INFO)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mH73ih9855Z2","colab_type":"code","colab":{}},"source":["# example tokenization\n","from transformers import BertTokenizer, BertModel, BertForMaskedLM\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n","tokenized_text = tokenizer.tokenize(text)\n","print(tokenized_text)\n","\n","masked_index = 8\n","tokenized_text[masked_index] = '[MASK]'\n","print(tokenized_text)\n","\n","indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n","tokens_tensor = torch.tensor([indexed_tokens])\n","print(tokens_tensor)\n","print(tokens_tensor.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YITbbsNm55Z3","colab_type":"code","colab":{}},"source":["# Load pre-trained model (weights)\n","model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n","model.eval()\n","\n","# If you have a GPU, put everything on cuda\n","tokens_tensor = tokens_tensor.to('cuda')\n","# segments_tensors = segments_tensors.to('cuda')\n","model.to('cuda')\n","\n","# Predict all tokens\n","with torch.no_grad():\n","#     outputs = model(tokens_tensor, token_type_ids=segments_tensors)\n","    outputs = model(tokens_tensor)\n","    predictions = outputs[0]\n","\n","# confirm we were able to predict 'henson'\n","predicted_index = torch.argmax(predictions[0, masked_index]).item()\n","predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n","print(predicted_token)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fd21GWBz55Z6","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ezPuox855Z8","colab_type":"code","outputId":"fab38698-1d71-45cb-ec06-f869068dd13b","executionInfo":{"status":"ok","timestamp":1571673957351,"user_tz":240,"elapsed":283731,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# GPT-2\n","\n","import torch\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","\n","# Load pre-trained model tokenizer (vocabulary)\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2-large')\n","\n","# Load pre-trained model (weights)\n","model = GPT2LMHeadModel.from_pretrained('gpt2-large')\n","\n","\n","# Set the model in evaluation mode to deactivate the DropOut modules\n","# This is IMPORTANT to have reproducible results during evaluation!\n","model.eval()\n","model.to('cuda')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 1042301/1042301 [00:01<00:00, 937069.71B/s]\n","100%|██████████| 456318/456318 [00:00<00:00, 500226.97B/s]\n","100%|██████████| 529/529 [00:00<00:00, 227614.57B/s]\n","100%|██████████| 3247202234/3247202234 [03:41<00:00, 14645396.05B/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(50257, 1280)\n","    (wpe): Embedding(1024, 1280)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (12): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (13): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (14): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (15): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (16): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (17): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (18): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (19): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (20): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (21): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (22): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (23): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (24): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (25): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (26): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (27): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (28): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (29): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (30): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (31): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (32): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (33): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (34): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (35): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=1280, out_features=50257, bias=False)\n",")"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"Fj4V8Z8255Z_","colab_type":"code","colab":{}},"source":["# original_text = \"Martin Steinegger is in Peru because he \"\n","# original_text = \"The real reason Steven keeps recruiting German postdocs is \"\n","# original_text = \"The secret to giving a fun and compelling Joint Lab Meeting presentation is \"\n","# original_text = \"UC Berkeley is\"\n","# original_text = \"Why did Donald Trump \"\n","# original_text = \"Finding genes is easy... The secret is \"\n","# original_text = \"Computational gene finding is easy, the problem is \"\n","# original_text = \"The future of Biomedical Engineering is \"\n","# original_text = \"The best way to describe how neural networks work is \"\n","original_text = \"Improving on state-of-the-art bacterial gene finding programs is hard, \"\n","\n","\n","text = original_text\n","for i in range(20): # not the best way to iterate, but it works\n","    if text[-1] != \".\":\n","        # Encode a text inputs\n","        indexed_tokens = tokenizer.encode(text)\n","\n","        # Convert indexed tokens in a PyTorch tensor\n","        tokens_tensor = torch.tensor([indexed_tokens])\n","\n","        # If you have a GPU, put everything on cuda\n","        tokens_tensor = tokens_tensor.to('cuda')\n","\n","        # Predict all tokens\n","        with torch.no_grad():\n","            outputs = model(tokens_tensor)\n","            predictions = outputs[0]\n","\n","        # get the predicted next sub-word (in our case, the word 'man')\n","        predicted_index = torch.argmax(predictions[0, -1, :]).item()\n","        predicted_text = tokenizer.decode(indexed_tokens + [predicted_index])\n","\n","        text = predicted_text"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GnlswbS155aA","colab_type":"code","outputId":"7ed70e38-64f6-4c01-861d-013d549c29bf","colab":{}},"source":["print(\"Original text:\\t\\t\", original_text)\n","print(\"Completed sentence:\\t\", predicted_text)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Original text:\t\t Improving on state-of-the-art bacterial gene finding programs is hard, \n","Completed sentence:\t Improving on state-of-the-art bacterial gene finding programs is hard, but it's not impossible.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AT2RmpXZ55aC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FFR-o-dr55aD","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KKSSFryL55aE","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aqxg6dGV55aF","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aUvkNFcZ55aH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vn9QworP55aI","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7br8_zL55aL","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0t_F1Fno55aL","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ru6wfCmi55aN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}