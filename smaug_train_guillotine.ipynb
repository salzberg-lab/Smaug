{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"smaug_train_guillotine.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"OS2_jqaAGq2q","colab_type":"code","outputId":"afd4e3d0-72ca-46a7-b2bd-6a6e72160491","executionInfo":{"status":"ok","timestamp":1575842105012,"user_tz":300,"elapsed":3004,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Sun Dec  8 21:55:03 2019       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.33.01    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   47C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LfDztkj3muhS","colab_type":"code","outputId":"39d3d431-43ec-4a2d-88c8-ee6f538deb67","executionInfo":{"status":"ok","timestamp":1575842138872,"user_tz":300,"elapsed":31172,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ga8mM1hmmisE","colab_type":"code","outputId":"58c7b9e9-1458-46e3-ad61-b0e0e82e42a4","executionInfo":{"status":"ok","timestamp":1575842121536,"user_tz":300,"elapsed":15066,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":714}},"source":["!pip install biopython\n","!pip install transformers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting biopython\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/01/7e5858a1e54bd0bd0d179cd74654740f07e86fb921a43dd20fb8beabe69d/biopython-1.75-cp36-cp36m-manylinux1_x86_64.whl (2.3MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 2.7MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from biopython) (1.17.4)\n","Installing collected packages: biopython\n","Successfully installed biopython-1.75\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/1a/364556102943cacde1ee00fdcae3b1615b39e52649eddbf54953e5b144c9/transformers-2.2.1-py3-none-any.whl (364kB)\n","\u001b[K     |████████████████████████████████| 368kB 2.7MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 50.2MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.4)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.32)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n","\u001b[K     |████████████████████████████████| 860kB 37.7MB/s \n","\u001b[?25hCollecting regex\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n","\u001b[K     |████████████████████████████████| 645kB 42.4MB/s \n","\u001b[?25hRequirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n","Requirement already satisfied: botocore<1.14.0,>=1.13.32 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.32)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.0)\n","Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->transformers) (2.6.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->transformers) (0.15.2)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=b777ee658b17c2154c3b21fa4cd4bc6436e37e5a626f05c664d536b5614df54a\n","  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, sacremoses, regex, transformers\n","Successfully installed regex-2019.11.1 sacremoses-0.0.35 sentencepiece-0.1.83 transformers-2.2.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nq_dBVgkmuer","colab_type":"code","outputId":"7f2844ad-e727-489e-82e4-dab273aa1fe2","executionInfo":{"status":"ok","timestamp":1575842148025,"user_tz":300,"elapsed":4858,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":63}},"source":["import os\n","import sys\n","import pickle\n","import torch\n","import numpy as np\n","import torch.optim as optim\n","# from transformers import BertConfig, BertModel, BertForMaskedLM\n","from transformers import GPT2Config, GPT2Model, GPT2LMHeadModel\n","from Bio import SeqIO\n","from Bio.Data import CodonTable\n","\n","from IPython.display import clear_output"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"8kThyCu_jGLL","colab_type":"code","colab":{}},"source":["# load genes and fake ORFs\n","d = \"drive/My Drive/Colab Notebooks/smaug/data\"\n","gene_ORF_path = os.path.join(d, \"ecoli_MG1655_geneORFs.pkl\")\n","fake_ORF_path = os.path.join(d, \"ecoli_MG1655_fakeORFs.pkl\")\n","# gene_ORF_path = os.path.join(d, \"Staphylococcus_geneORFs.pkl\")\n","# fake_ORF_path = os.path.join(d, \"Staphylococcus_fakeORFs.pkl\")\n","\n","with open(gene_ORF_path, 'rb') as f:\n","    gene_aa_filtered = pickle.load(f)\n","with open(fake_ORF_path, 'rb') as f:\n","    fake_aa = pickle.load(f)\n","\n","gene_aa_filtered = [x for x in gene_aa_filtered if len(x) > 40]\n","fake_aa = [x for x in fake_aa if len(x) > 40] # already filtered for length at creation time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pwbkuzkuzWds","colab_type":"code","colab":{}},"source":["def tokenize_aa_seq(aa_seq):\n","    \"\"\"Convert amino acid letters to integers. Can also use murphy's reduced aa alphabet later\"\"\"\n","    table = {\"L\":1,\n","             \"V\":2,\n","             \"I\":3,\n","             \"M\":4,\n","             \"C\":5,\n","             \"A\":6,\n","             \"G\":7,\n","             \"S\":8,\n","             \"T\":9,\n","             \"P\":10,\n","             \"F\":11,\n","             \"Y\":12,\n","             \"W\":13,\n","             \"E\":14,\n","             \"D\":15,\n","             \"N\":16,\n","             \"Q\":17,\n","             \"K\":18,\n","             \"R\":19,\n","             \"H\":20,\n","             \"X\":0, # get rid of these\n","             \"B\":0,\n","             \"*\":0}\n","    tokenized = torch.tensor([table[aa] for aa in aa_seq])\n","    return tokenized"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NHrhoe8fy_T1","colab_type":"code","outputId":"ff6c5ee1-d6d6-4568-d556-f23744eedd5e","executionInfo":{"status":"ok","timestamp":1575842174418,"user_tz":300,"elapsed":4995,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":595}},"source":["# split long ORFs into shingles\n","\n","# TODO: this was done in time crunch, should not be done like this. Redo\n","SHINGLE_STEP = 10\n","SHINGLE_LENGTH = 20 # shingle length should be the same as trained model window size\n","\n","ORF_shingled = []\n","for i, ORFseq in enumerate(gene_aa_filtered):\n","    if i%1000==0:\n","        print(i)\n","    ORF_shingled_temp = []\n","    while True:\n","        shingle = ORFseq[:SHINGLE_LENGTH]\n","        shingle_int = tokenize_aa_seq(shingle)\n","        ORF_shingled_temp.append(shingle_int)\n","        if len(ORFseq) > SHINGLE_LENGTH + SHINGLE_STEP:\n","            ORFseq = ORFseq[SHINGLE_STEP:]\n","        else:\n","            break\n","    shingle_last = ORFseq[-(SHINGLE_LENGTH):]\n","    shingle_int =  tokenize_aa_seq(shingle_last)\n","    ORF_shingled_temp.append(shingle_int)\n","    \n","    ORF_shingled.append(ORF_shingled_temp)\n","# flatten shingles to submit to GPU\n","# keep track of which shingles belong to which ORFs\n","combined = [torch.stack(x, dim=0) for x in ORF_shingled]\n","combined_shape = [len(x) for x in combined]\n","\n","ORF_flat = torch.cat(combined, dim=0)\n","\n","# ARFs\n","ARF_shingled = []\n","for i, ARFseq in enumerate(fake_aa):\n","    if i%1000==0:\n","        print(i)\n","    ARF_shingled_temp = []\n","    while True:\n","        shingle = ARFseq[:SHINGLE_LENGTH]\n","        shingle_int = tokenize_aa_seq(shingle)\n","        ARF_shingled_temp.append(shingle_int)\n","        if len(ARFseq) > SHINGLE_LENGTH + SHINGLE_STEP:\n","            ARFseq = ARFseq[SHINGLE_STEP:]\n","        else:\n","            break\n","    shingle_last = ARFseq[-(SHINGLE_LENGTH):]\n","    shingle_int =  tokenize_aa_seq(shingle_last)\n","    ARF_shingled_temp.append(shingle_int)\n","    \n","    ARF_shingled.append(ARF_shingled_temp)\n","# flatten shingles to submit to GPU\n","# keep track of which shingles belong to which ORFs\n","combined = [torch.stack(x, dim=0) for x in ARF_shingled]\n","combined_shape = [len(x) for x in combined]\n","\n","ARF_flat = torch.cat(combined, dim=0)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["0\n","1000\n","2000\n","3000\n","0\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EE8ifAqP0pm5","colab_type":"code","outputId":"b7e9d091-b942-4cdc-f9c5-af88f0e39128","executionInfo":{"status":"ok","timestamp":1575842178631,"user_tz":300,"elapsed":1229,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# split into training and test with gene labels\n","data_X = torch.cat((ORF_flat, ARF_flat))\n","# data_X = torch.cat((ORF_flat, ARF_flat)).type(torch.long)\n","data_y = torch.cat((torch.ones(len(ORF_flat), dtype=int), torch.zeros(len(ARF_flat), dtype=int))) # 1=gene, 0=arf\n","\n","np.random.seed(2019)\n","# select_idx = np.random.randint(0, len(data_X), int(0.8*len(data_X)))\n","select_idx = np.random.choice(range(len(data_X)), size=int(0.8*len(data_X)), replace=False)\n","dtrain_X = data_X[select_idx]\n","dtrain_y = data_y[select_idx].reshape(-1,1)\n","\n","inverse_select_idx = np.ones(len(data_X), dtype=bool)\n","inverse_select_idx[select_idx] = 0\n","dvalid_X = data_X[inverse_select_idx]\n","dvalid_y = data_y[inverse_select_idx].reshape(-1,1)\n","\n","rand_idx = np.random.choice(range(len(dvalid_X)), size=int(len(dvalid_X)), replace=False)\n","dvalid_X = dvalid_X[rand_idx]\n","dvalid_y = dvalid_y[rand_idx]\n","\n","print(len(data_X), len(dtrain_X), len(dvalid_X), len(dtrain_X)+len(dvalid_X))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["289739 231791 57948 289739\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ly1gTJK1xGsz","colab_type":"code","colab":{}},"source":["# Teach the new head how to classify genes"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QoKRDw4FHK4m","colab_type":"code","colab":{}},"source":["# from transformers import BertForSequenceClassification\n","\n","# examplemodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n","# print(examplemodel)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fi1kr1YHK0g","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PDhBN0twLWj5","colab_type":"code","outputId":"ea2149ee-73a5-46f7-cff0-f5eccf7c80ff","executionInfo":{"status":"ok","timestamp":1575842377627,"user_tz":300,"elapsed":1149,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["class GeneBinaryClassifier(torch.nn.Module):\n","    \"\"\" customize GPT2 model for classification \"\"\"\n","    def __init__(self, pretrained_path, hidden_dim):\n","        super(GeneBinaryClassifier, self).__init__()\n","        self.model = GPT2LMHeadModel.from_pretrained(pretrained_path)\n","        self.model.config.output_hidden_states = False\n","\n","        self.removed = list(self.model.children())[:-1] # remove last layer\n","        self.model= torch.nn.Sequential(*self.removed)\n","\n","        # for param in self.model.parameters(): # freeze all pretrained layers\n","        #     param.requires_grad = False, TODO: empirically this kills the model almost entirely, why?\n","\n","        self.fc = torch.nn.Linear(hidden_dim, hidden_dim, bias=False) # add fully connected layer\n","        # self.activation = torch.nn.Sigmoid() # similar to BERT, https://github.com/google-research/bert/issues/43\n","        # self.activation = torch.nn.Tanh() # similar to BERT, https://github.com/google-research/bert/issues/43\n","\n","        self.classifier = torch.nn.Linear(hidden_dim, 1) # TODO: compare BCEWithLogitsLoss on 1 node to Cross Entropy on 2 nodes\n","    \n","    def forward(self, X):\n","        y_transformer, _ = self.model(X)\n","        y_last = y_transformer[:, -1] # take only the hidden state of the last token (similar to BERT taking only first token)\n","        y_fc = self.fc(y_last)\n","        # y_act = self.activation(y_fc)\n","        # y_class = self.classifier(y_act)\n","        y_class = self.classifier(y_fc)\n","        return y_class\n","\n","# modeldir = \"drive/My Drive/Colab Notebooks/smaug/data/models/ecoli_trivial_length40_overlap_20\"\n","modeldir = \"drive/My Drive/Colab Notebooks/smaug/data/models/ecoli_trivial_length20_overlap10\"\n","\n","hidden_dim = 16\n","genemodel = GeneBinaryClassifier(modeldir, hidden_dim).to(\"cuda\")\n","print(genemodel)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["GeneBinaryClassifier(\n","  (model): Sequential(\n","    (0): GPT2Model(\n","      (wte): Embedding(21, 16)\n","      (wpe): Embedding(20, 16)\n","      (drop): Dropout(p=0, inplace=False)\n","      (h): ModuleList(\n","        (0): Block(\n","          (ln_1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","          (attn): Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0, inplace=False)\n","            (resid_dropout): Dropout(p=0, inplace=False)\n","          )\n","          (ln_2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","          (mlp): MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (dropout): Dropout(p=0, inplace=False)\n","          )\n","        )\n","        (1): Block(\n","          (ln_1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","          (attn): Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0, inplace=False)\n","            (resid_dropout): Dropout(p=0, inplace=False)\n","          )\n","          (ln_2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","          (mlp): MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (dropout): Dropout(p=0, inplace=False)\n","          )\n","        )\n","        (2): Block(\n","          (ln_1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","          (attn): Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0, inplace=False)\n","            (resid_dropout): Dropout(p=0, inplace=False)\n","          )\n","          (ln_2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","          (mlp): MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (dropout): Dropout(p=0, inplace=False)\n","          )\n","        )\n","        (3): Block(\n","          (ln_1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","          (attn): Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0, inplace=False)\n","            (resid_dropout): Dropout(p=0, inplace=False)\n","          )\n","          (ln_2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","          (mlp): MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (dropout): Dropout(p=0, inplace=False)\n","          )\n","        )\n","        (4): Block(\n","          (ln_1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","          (attn): Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0, inplace=False)\n","            (resid_dropout): Dropout(p=0, inplace=False)\n","          )\n","          (ln_2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","          (mlp): MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (dropout): Dropout(p=0, inplace=False)\n","          )\n","        )\n","        (5): Block(\n","          (ln_1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","          (attn): Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0, inplace=False)\n","            (resid_dropout): Dropout(p=0, inplace=False)\n","          )\n","          (ln_2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","          (mlp): MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (dropout): Dropout(p=0, inplace=False)\n","          )\n","        )\n","        (6): Block(\n","          (ln_1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","          (attn): Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0, inplace=False)\n","            (resid_dropout): Dropout(p=0, inplace=False)\n","          )\n","          (ln_2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","          (mlp): MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (dropout): Dropout(p=0, inplace=False)\n","          )\n","        )\n","        (7): Block(\n","          (ln_1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","          (attn): Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0, inplace=False)\n","            (resid_dropout): Dropout(p=0, inplace=False)\n","          )\n","          (ln_2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","          (mlp): MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (dropout): Dropout(p=0, inplace=False)\n","          )\n","        )\n","        (8): Block(\n","          (ln_1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","          (attn): Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0, inplace=False)\n","            (resid_dropout): Dropout(p=0, inplace=False)\n","          )\n","          (ln_2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","          (mlp): MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (dropout): Dropout(p=0, inplace=False)\n","          )\n","        )\n","        (9): Block(\n","          (ln_1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","          (attn): Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0, inplace=False)\n","            (resid_dropout): Dropout(p=0, inplace=False)\n","          )\n","          (ln_2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","          (mlp): MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (dropout): Dropout(p=0, inplace=False)\n","          )\n","        )\n","        (10): Block(\n","          (ln_1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","          (attn): Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0, inplace=False)\n","            (resid_dropout): Dropout(p=0, inplace=False)\n","          )\n","          (ln_2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","          (mlp): MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (dropout): Dropout(p=0, inplace=False)\n","          )\n","        )\n","        (11): Block(\n","          (ln_1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","          (attn): Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0, inplace=False)\n","            (resid_dropout): Dropout(p=0, inplace=False)\n","          )\n","          (ln_2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","          (mlp): MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (dropout): Dropout(p=0, inplace=False)\n","          )\n","        )\n","      )\n","      (ln_f): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (fc): Linear(in_features=16, out_features=16, bias=False)\n","  (classifier): Linear(in_features=16, out_features=1, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4NfXwy6pxqTp","colab_type":"code","colab":{}},"source":["optimizer = optim.AdamW(genemodel.parameters())\n","\n","# optimizer = optim.SGD(genemodel.parameters(), lr=0.001, momentum=0.9)\n","\n","# criterion = torch.nn.CrossEntropyLoss()\n","# criterion = torch.nn.BCELoss()\n","criterion = torch.nn.BCEWithLogitsLoss()\n","\n","exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X5fsyzmn_woz","colab_type":"code","colab":{}},"source":["def savemodel(model):\n","    # save model\n","    # Load the Drive helper and mount\n","    from google.colab import drive\n","\n","    # This will prompt for authorization.\n","    drive.mount('/content/drive')\n","\n","    # modeldir = \"drive/My Drive/Colab Notebooks/smaug/data/models/ecoli_trivial_length40_overlap20_guillotine\"\n","    modeldir = \"drive/My Drive/Colab Notebooks/smaug/data/models/ecoli_trivial_length20_overlap10_guillotine\"\n","    p = os.path.join(modeldir, \"model\")\n","    with open(p, \"wb\") as f:\n","        torch.save(model, f)\n","    # model.config.save_pretrained(modeldir)\n","    print(os.listdir(modeldir))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C1melqZmwtXw","colab_type":"code","outputId":"fdb21a23-044d-48d8-9c89-6a8f5c371850","executionInfo":{"status":"error","timestamp":1575842691386,"user_tz":300,"elapsed":880,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["# retrain model\n","genemodel.train()\n","\n","batch_size = 2**9\n","\n","optimizer.zero_grad()\n","for i in range(int(1e10)):\n","    if i%500==100:\n","        savemodel(genemodel)\n","    optimizer.zero_grad()\n","\n","    select_idx = np.random.randint(0, len(dtrain_X), batch_size)\n","\n","#     input_ids = dtrain[select_idx].unsqueeze(0) # singleton\n","    input_ids = dtrain_X[select_idx].to('cuda')\n","    input_labels = dtrain_y[select_idx].type(torch.float32).to('cuda')\n","    \n","    outputs = genemodel(input_ids)\n","    \n","    loss = criterion(outputs, input_labels)\n","    \n","    loss.backward()\n","    optimizer.step()\n","    \n","    clear_output(wait=True)\n","    print(\"Iteration:\", i, \"; Loss:\", loss.item())"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Iteration: 114 ; Loss: 0.3317720293998718\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-ee0777ec0628>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"mHZkdP7mYPeX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":391},"outputId":"633eec94-df06-46d8-a123-d38684ce626a","executionInfo":{"status":"ok","timestamp":1575833394811,"user_tz":300,"elapsed":878,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}}},"source":["print(outputs.dtype)\n","print(input_labels.dtype)\n","# print(-torch.log(torch.sigmoid(outputs[:10])))\n","print(torch.sigmoid(outputs[:10]))\n","# print(outputs[:10])\n","\n","print(input_labels[:10])"],"execution_count":15,"outputs":[{"output_type":"stream","text":["torch.float32\n","torch.float32\n","tensor([[9.8483e-01],\n","        [8.5497e-03],\n","        [1.2257e-04],\n","        [9.9845e-01],\n","        [4.7623e-05],\n","        [1.3472e-04],\n","        [9.9974e-01],\n","        [3.8654e-05],\n","        [6.7991e-04],\n","        [9.8174e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)\n","tensor([[1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.]], device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eIJyf7i8YPPI","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HksF_M59YPMP","colab_type":"code","colab":{}},"source":["import seaborn as sns\n","from sklearn import metrics\n","import matplotlib.pyplot as plt \n","\n","def plot_ROC(y_true, y_pred_score):\n","    fpr, tpr, _ = metrics.roc_curve(y_true, y_pred_score)\n","    roc_auc = metrics.auc(fpr, tpr)\n","\n","    plt.figure()\n","    lw = 2\n","    plt.plot(fpr, tpr, color='darkorange',\n","            lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n","    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver operating characteristic example')\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","def plot_hist(y_true, y_pred_score):\n","    scores_GENE = y_pred_score[y_true==1]\n","    scores_ARF = y_pred_score[y_true==0]\n","\n","    # sns.distplot(scores_GENE, hist = False, kde = True,\n","    #             kde_kws = {'shade': True, 'linewidth': 3}, \n","    #             label = 'gene')\n","    # sns.distplot(scores_ARF, hist = False, kde = True,\n","    #             kde_kws = {'shade': True, 'linewidth': 3}, \n","    #             label = 'ARF')\n","    \n","    # # plt.xlim([0.04,0.09])\n","    # plt.xlim([-0.1, 1.1])\n","    # plt.show()\n","\n","    bins = np.linspace(0, 1, 100)\n","    plt.hist(scores_GENE, bins, alpha=0.5, label=\"Gene\")\n","    plt.hist(scores_ARF, bins, alpha=0.5, label=\"ARF\")\n","    plt.legend(loc='upper right')\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kAIYxJu1zzSu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":214},"outputId":"7f250bf0-725b-46a3-d1fd-f77473c474b4","executionInfo":{"status":"error","timestamp":1575840375795,"user_tz":300,"elapsed":1111,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}}},"source":["# evaluate new head model\n","def evaluate(model, X, y, BATCH_SIZE):\n","    model.eval()\n","\n","    outputs = []\n","    for i in range(0, len(X), BATCH_SIZE):\n","        if i%1000==0:\n","            print(i)\n","        out = model(X[i:i+BATCH_SIZE].to(\"cuda\")).to(\"cpu\")\n","        outputs.append(out)\n","    outputs = torch.cat(outputs, dim=0)\n","\n","\n","\n","    y_pred = torch.sigmoid(outputs).detach().numpy()\n","    plot_ROC(y, y_pred)\n","    plot_hist(y, y_pred)\n","    \n","BATCH_SIZE = 2\n","total = 1000\n","evaluate(genemodel, dtrain_X[:total], dtrain_y[:total], BATCH_SIZE)\n","# evaluate(genemodel, dvalid_X[:total], dvalid_y[:total], BATCH_SIZE)"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-644c16391673>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenemodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m# evaluate(genemodel, dvalid_X[:total], dvalid_y[:total], BATCH_SIZE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'genemodel' is not defined"]}]},{"cell_type":"code","metadata":{"id":"VnAv6GcQw4Cs","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PxiTeQ_1700H","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nBksxXl870ap","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"86rE_AEx70WQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MKgorYOY70Tx","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PZgFaKuV70Rb","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YtWORCJ770O-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vE_OO4l47zc9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UHiuC2ON7zaL","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u0hrY0F27zXz","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qH4oDc7N7zWC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"98_pYmV47zTx","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7pMSWXew7zRY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-CN9YO5T7zPE","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BfcgotIqw4BU","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3oka7qbcw3-9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"za6Aa90Rw38s","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K-WZt2jiw37F","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ICk2XSWjw347","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6NDXv5xJw33b","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pBxDDSKZw31C","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sX9AXpWxw3zW","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eB8dUHp1wtP-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QY-itbuhwtNn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f-Vr717HjGBK","colab_type":"code","colab":{}},"source":["|"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B9MlYOB5mudK","colab_type":"code","colab":{}},"source":["# custom parameters for GPT2 model\n","vocab_size = 21\n","max_position_embeddings = 20 # 1024\n","n_ctw = max_position_embeddings # 1024\n","n_embd = 16 # 768\n","n_layer = 8 # 12\n","n_head = 8 # 12\n","resid_pdrop = 0 # 0.1\n","embd_pdrop = 0 # 0.1\n","attn_pdrop = 0 # 0.1\n","layer_norm_epsilon = 1e-5 # 1e-5\n","\n","\n","config = GPT2Config(vocab_size_or_config_json_file=vocab_size,\n","                    n_positions=max_position_embeddings,\n","                    n_ctw=n_ctw,\n","                    n_embd=n_embd,\n","                    n_layer=n_layer,\n","                    n_head=n_head, \n","                    resid_pdrop=resid_pdrop,\n","                    embd_pdrop=embd_pdrop,\n","                    attn_pdrop=attn_pdrop,\n","                    layer_norm_epsilon=layer_norm_epsilon)\n","\n","model = GPT2LMHeadModel(config)\n","\n","# print(model)\n","model.to('cuda')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l5Hy83Homuag","colab_type":"code","colab":{}},"source":["# load data\n","d = \"drive/My Drive/Colab Notebooks/smaug/data\"\n","shingle_path = os.path.join(d, \"ecoli_MG1655_shingles_length20_overlap10.npy\")\n","\n","with open(shingle_path, 'rb') as f:\n","    ecoli_shingles = np.load(shingle_path)#[:2056]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nPXHybK8muYV","colab_type":"code","colab":{}},"source":["# pass to GPU\n","tokens_tensor = torch.tensor(ecoli_shingles).to('cuda')\n","\n","\n","dtrain = tokens_tensor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I5r8Jf3pwpPX","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W4XFDO6wmuV8","colab_type":"code","colab":{}},"source":["optimizer = optim.AdamW(model.parameters())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T85Z_nICmuTq","colab_type":"code","colab":{}},"source":["def savemodel():\n","    # save model\n","    # Load the Drive helper and mount\n","    from google.colab import drive\n","\n","    # This will prompt for authorization.\n","    drive.mount('/content/drive')\n","\n","    modeldir = \"drive/My Drive/Colab Notebooks/smaug/data/models/ecoli_trivial_length20_overlap10\"\n","    model.save_pretrained(modeldir)\n","    print(os.listdir(modeldir))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lpCjshJ5muSY","colab_type":"code","colab":{}},"source":["# train model with single aa masked at a time ##### batch\n","model.train()\n","\n","batch_size = 2**14\n","\n","optimizer.zero_grad()\n","np.random.seed(42424)\n","for i in range(1000000):\n","    if i%500==10:\n","        savemodel()\n","    optimizer.zero_grad()\n","\n","    select_idx = np.random.randint(0, len(dtrain), batch_size)\n","\n","#     input_ids = dtrain[select_idx].unsqueeze(0) # singleton\n","    input_ids = dtrain[select_idx]\n","    \n","    \n","    outputs = model(input_ids, labels=input_ids)\n","    loss, prediction_scores = outputs[:2]\n","    \n","    loss.backward()\n","    optimizer.step()\n","    \n","    clear_output(wait=True)\n","    print(\"Loss:\", loss.item())\n","\n","    for k in range(10, 20):\n","#         print(i, torch.argmax(prediction_scores[0,k-1]).item(), input_ids[0,k].item(), \"\\t\", loss.item()) #TODO figure out why GPT2 only offsets sometimes\n","        print(i, \"\\t\", torch.argmax(prediction_scores[10,k-1]).item(), \"\\t\", input_ids[10,k].item(), \"\\t\")\n","#         print(prediction_scores[0])\n","    \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wM8OzcbZmuPg","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UXMCUDsjmuNZ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tRm7QgtSmuLV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NhYViNqFmuIx","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cm_KUnUPmuFM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}