{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"custom_mask_colab_GPT2.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"03irV-C_6jpZ","colab_type":"code","outputId":"8a947101-0a6f-400b-8308-80f84d531c39","executionInfo":{"status":"ok","timestamp":1571972152800,"user_tz":240,"elapsed":7770,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":612}},"source":["!pip install transformers"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/f9/51824e40f0a23a49eab4fcaa45c1c797cbf9761adedd0b558dab7c958b34/transformers-2.1.1-py3-none-any.whl (311kB)\n","\u001b[K     |████████████████████████████████| 317kB 3.5MB/s \n","\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.9.253)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n","\u001b[K     |████████████████████████████████| 860kB 41.0MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.3)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 34.8MB/s \n","\u001b[?25hCollecting regex\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/60/d9782c56ceefa76033a00e1f84cd8c586c75e6e7fea2cd45ee8b46a386c5/regex-2019.08.19-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n","\u001b[K     |████████████████████████████████| 645kB 37.1MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Requirement already satisfied: botocore<1.13.0,>=1.12.253 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.12.253)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.0)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.9.11)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.253->boto3->transformers) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.253->boto3->transformers) (2.6.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=9cdb0710c0f3a7005eed1c380bca7dc3e78f0a66679881e36d15ad6f27c54c90\n","  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, sentencepiece, regex, transformers\n","Successfully installed regex-2019.8.19 sacremoses-0.0.35 sentencepiece-0.1.83 transformers-2.1.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MTLDde1m6k_O","colab_type":"code","outputId":"e570ccf1-6fc2-45a9-df2f-79c40858f576","executionInfo":{"status":"ok","timestamp":1571972170483,"user_tz":240,"elapsed":24225,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X3i73FlB55Xt","colab_type":"code","colab":{}},"source":["import os\n","import sys\n","import pickle\n","import torch\n","import numpy as np\n","import torch.optim as optim\n","# from transformers import BertConfig, BertModel, BertForMaskedLM\n","from transformers import GPT2Config, GPT2Model, GPT2LMHeadModel\n","\n","from IPython.display import clear_output\n","\n","# import matplotlib.pyplot as plt\n","# from transformers import *"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kBbEF2Uc6lK5","colab_type":"code","outputId":"e2ffc1c5-3009-438d-dfa7-75594dc3c4c1","executionInfo":{"status":"ok","timestamp":1571972180796,"user_tz":240,"elapsed":658,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["d = \"drive/My Drive/Colab Notebooks/smaug/data\"\n","p = os.path.join(d, \"CDS_singlestrain_threeprime.pkl\")\n","print(os.listdir(d))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['CDS_singlestrain_threeprime.pkl', 'models', 'config.json', 'pytorch_model.bin']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cA49xxRjaakk","colab_type":"code","colab":{}},"source":["with open(p, 'rb') as f:\n","  CDS = pickle.load(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XXjv4EukaaiC","colab_type":"code","outputId":"399bc8dd-006a-43a1-9587-fadae5f48eb3","executionInfo":{"status":"ok","timestamp":1571972231706,"user_tz":240,"elapsed":50232,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["print(type(CDS))\n","print(len(CDS))\n","print(CDS[100])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<class 'list'>\n","9304394\n","HVSLLSVHAAVAVWRKKRQMYIDQYCVRGTKLTNAEKFVFTMYATVVGIKEDLMRVDASDINVSLIEQRRLNRIVDRRTMKNGDPSILIFDNAFIRELTVSDKSPYSRIWDENMRKLTEVSKNQAHLQCTFVMVLSFLLIAKM\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KVf-Zgp255X6","colab_type":"code","colab":{}},"source":["# lengths = [len(s) for s in CDS]\n","# meanlen = np.mean(lengths)\n","# medlen = np.median(lengths)\n","# minlen = np.min(lengths)\n","# maxlen = np.max(lengths)\n","# print(meanlen, medlen, minlen, maxlen)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EmIQPDvZ55X9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YMj7-AzZ55YA","colab_type":"code","colab":{}},"source":["# import logging\n","# logging.basicConfig(level=logging.INFO)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dvEYlPOb55YD","colab_type":"code","colab":{}},"source":["# # custom parameters for BERT model\n","# vocab_size = 12 # Vocabulary size of inputs_ids in BertModel. default=30522\n","# hidden_size = 768 # Size of the encoder layers and the pooler layer, default=768\n","# num_hidden_layers = 12 # Number of hidden layers in the Transformer encoder. default=12\n","# num_attention_heads = 12 # Number of attention heads for each attention layer in the Transformer encoder, default=12\n","# intermediate_size = 3072 # The size of the “intermediate” (i.e., feed-forward) layer in the Transformer encoder. default=3072\n","# hidden_act = \"gelu\" # The non-linear activation function (function or string) in the encoder and pooler. If string, “gelu”, “relu”, “swish” and “gelu_new” are supported. default=\"gelu\"\n","# hidden_dropout_prob = 0.1 # The dropout probabilitiy for all fully connected layers in the embeddings, encoder, and pooler. default=0.1\n","# attention_probs_dropout_prob = 0.1 # The dropout ratio for the attention probabilities. default=0.1\n","# max_position_embeddings = 512 # The maximum sequence length that this model might ever be used with. Typically set this to something large just in case (e.g., 512 or 1024 or 2048). default=512\n","# type_vocab_size = 2 # 1 # The vocabulary size of the token_type_ids passed into BertModel. default=2\n","# initializer_range = 0.02 # The sttdev of the truncated_normal_initializer for initializing all weight matrices. default=0.02\n","# layer_norm_eps = 1e-12 # The epsilon used by LayerNorm. default=1e-12\n","\n","\n","# config = BertConfig(vocab_size_or_config_json_file=vocab_size,\n","#                     hidden_size=hidden_size,\n","#                     num_hidden_layers=num_hidden_layers,\n","#                     num_attention_heads=num_attention_heads,\n","#                     intermediate_size=intermediate_size,\n","#                     hidden_act=hidden_act,\n","#                     hidden_dropout_prob=hidden_dropout_prob,\n","#                     attention_probs_dropout_prob=attention_probs_dropout_prob,\n","#                     max_position_embeddings=max_position_embeddings,\n","#                     type_vocab_size=type_vocab_size,\n","#                     initializer_range=initializer_range,\n","#                     layer_norm_eps=layer_norm_eps)\n","\n","# model = BertForMaskedLM(config)\n","\n","# print(model)\n","# model.to('cuda')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8Ra4nFr55YF","colab_type":"code","outputId":"b6817e5a-2823-4003-91be-0aede7d68ea8","executionInfo":{"status":"ok","timestamp":1571972238998,"user_tz":240,"elapsed":7283,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# custom parameters for GPT2 model\n","vocab_size = 22\n","max_position_embeddings = 40 # 1024\n","n_ctw = max_position_embeddings # 1024\n","n_embd = 36 # 768\n","n_layer = 12 # 12\n","n_head = 12 # 12\n","\n","\n","config = GPT2Config(vocab_size_or_config_json_file=vocab_size,\n","                    n_positions=max_position_embeddings,\n","                    n_ctw=n_ctw,\n","                    n_embd=n_embd,\n","                    n_layer=n_layer,\n","                    n_head=n_head)\n","\n","model = GPT2LMHeadModel(config)\n","\n","print(model)\n","model.to('cuda')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(22, 36)\n","    (wpe): Embedding(40, 36)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=36, out_features=22, bias=False)\n",")\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(22, 36)\n","    (wpe): Embedding(40, 36)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=36, out_features=22, bias=False)\n",")"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"rf0FLgnQ55YI","colab_type":"code","outputId":"275a7909-c863-46da-f9cd-b396dd2d7dac","executionInfo":{"status":"ok","timestamp":1571972301432,"user_tz":240,"elapsed":69704,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["# encode data as GPU tensors\n","max_aa_seq_length = max_position_embeddings\n","\n","\n","def tokenize_aa_seq_murphy10(aa_seq):\n","    table = {\"L\":1,\n","             \"V\":1,\n","             \"I\":1,\n","             \"M\":1,\n","             \"C\":2,\n","             \"A\":3,\n","             \"G\":4,\n","             \"S\":5,\n","             \"T\":5,\n","             \"P\":6,\n","             \"F\":7,\n","             \"Y\":7,\n","             \"W\":7,\n","             \"E\":8,\n","             \"D\":8,\n","             \"N\":8,\n","             \"Q\":8,\n","             \"K\":9,\n","             \"R\":9,\n","             \"H\":10,\n","             \"X\":0, # get rid of those\n","             \"B\":0,\n","             \"*\":0}\n","    tokenized = [table[aa] for aa in aa_seq]\n","    return tokenized\n","\n","def tokenize_aa_seq(aa_seq):\n","    table = {\"L\":1,\n","             \"V\":2,\n","             \"I\":3,\n","             \"M\":4,\n","             \"C\":5,\n","             \"A\":6,\n","             \"G\":7,\n","             \"S\":8,\n","             \"T\":9,\n","             \"P\":10,\n","             \"F\":11,\n","             \"Y\":12,\n","             \"W\":13,\n","             \"E\":14,\n","             \"D\":15,\n","             \"N\":16,\n","             \"Q\":17,\n","             \"K\":18,\n","             \"R\":19,\n","             \"H\":20,\n","             \"X\":0, # get rid of those\n","             \"B\":0,\n","             \"*\":0}\n","    tokenized = [table[aa] for aa in aa_seq]\n","    return tokenized\n","\n","# tokens = [tokenize_aa_seq_murphy10(seq) for seq in CDS[:1000]] ######################################\n","tokens = [tokenize_aa_seq(seq) for seq in CDS[:100000]] ######################################\n","\n","tokens_tensor = torch.zeros(len(tokens), max_aa_seq_length, dtype=torch.long)\n","for i in range(len(tokens)):\n","    l = len(tokens[i]) # scuff way to ensure fit in tensor, TODO build correctly sized data set and split into train test\n","    if l > max_aa_seq_length:\n","        l = max_aa_seq_length\n","    for j in range(l):\n","        tokens_tensor[i][j] += tokens[i][j]\n","\n","tokens_tensor = tokens_tensor.to('cuda')\n","\n","print(tokens_tensor)\n","print(tokens_tensor.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[18,  1,  4,  ...,  6, 11,  8],\n","        [ 6, 17,  6,  ..., 11,  5,  7],\n","        [15, 19,  1,  ..., 10, 14, 20],\n","        ...,\n","        [15, 18,  6,  ..., 11, 15, 18],\n","        [18, 14, 14,  ...,  3, 14,  9],\n","        [ 6, 16,  6,  ...,  3,  8,  5]], device='cuda:0')\n","torch.Size([100000, 40])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zlHdsHkb55YM","colab_type":"code","outputId":"021ffd66-3c37-4728-cdae-7425623bc20a","executionInfo":{"status":"ok","timestamp":1571972301433,"user_tz":240,"elapsed":69694,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["dtrain = tokens_tensor[:int(0.8*len(tokens_tensor))] #TODO do an actual random selection on better data\n","dvalid = tokens_tensor[int(0.8*len(tokens_tensor)):]\n","print(len(dtrain))\n","print(len(dvalid))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["80000\n","20000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fXThUjamEcFX","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KUuZzFiD55YQ","colab_type":"code","colab":{}},"source":["# optimizer = optim.SGD(model.parameters(), lr=0.0001)#, momentum=args.momentum)\n","optimizer = optim.AdamW(model.parameters())\n","# optimizer = optim.Adam(model.parameters())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fnFVcaYf2D6t","colab_type":"code","colab":{}},"source":["def savemodel():\n","    # save model\n","    # Load the Drive helper and mount\n","    from google.colab import drive\n","\n","    # This will prompt for authorization.\n","    drive.mount('/content/drive')\n","\n","    modeldir = \"drive/My Drive/Colab Notebooks/smaug/data/models\"\n","    model.save_pretrained(modeldir)\n","    print(os.listdir(modeldir))\n","    # p = os.path.join(d, \"CDS_singlestrain_threeprime.pkl\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fUCw7GIA9vDL","colab_type":"code","outputId":"a99a0bcf-9554-4a18-dac6-4701b92cb64c","executionInfo":{"status":"error","timestamp":1572011355530,"user_tz":240,"elapsed":366,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":399}},"source":["# train model with single aa masked at a time ##### batch\n","model.train()\n","\n","batch_size = 2**10\n","\n","optimizer.zero_grad()\n","np.random.seed(42424)\n","for i in range(100000):\n","    if i%500==10:\n","        savemodel()\n","    optimizer.zero_grad()\n","\n","    select_idx = np.random.randint(0, len(dtrain), batch_size)\n","\n","#     input_ids = dtrain[select_idx].unsqueeze(0) # singleton\n","    input_ids = dtrain[select_idx]\n","    \n","    \n","    outputs = model(input_ids, labels=input_ids)\n","    loss, prediction_scores = outputs[:2]\n","    \n","    loss.backward()\n","    optimizer.step()\n","    \n","    clear_output(wait=True)\n","    for k in range(0, 10):\n","#         print(i, torch.argmax(prediction_scores[0,k-1]).item(), input_ids[0,k].item(), \"\\t\", loss.item()) #TODO figure out why GPT2 only offsets sometimes\n","        print(i, \"\\t\", torch.argmax(prediction_scores[0,k-1]).item(), \"\\t\", input_ids[0,k].item(), \"\\t\", loss.item())\n","#         print(prediction_scores[0])\n","    \n"],"execution_count":30,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-651af3feaca7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past, attention_mask, token_type_ids, position_ids, head_mask, labels)\u001b[0m\n\u001b[1;32m    531\u001b[0m                                                \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                                                \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m                                                head_mask=head_mask)\n\u001b[0m\u001b[1;32m    534\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past, attention_mask, token_type_ids, position_ids, head_mask)\u001b[0m\n\u001b[1;32m    439\u001b[0m                             \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                             head_mask=head_mask[i])\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, layer_past, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    229\u001b[0m                                 \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                                 head_mask=head_mask)\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_attn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# output_attn: a, present, (attentions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, layer_past, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mpresent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# transpose to have same shapes for stacking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mattn_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_gpt2.py\u001b[0m in \u001b[0;36m_attn\u001b[0;34m(self, q, k, v, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 76.00 MiB (GPU 0; 11.17 GiB total capacity; 9.60 GiB already allocated; 11.81 MiB free; 1.25 GiB cached)"]}]},{"cell_type":"code","metadata":{"id":"7CIuq8j7TYz4","colab_type":"code","outputId":"1e5542da-dd82-407f-fe62-32ed90051795","executionInfo":{"status":"ok","timestamp":1572003050676,"user_tz":240,"elapsed":2081,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# save model\n","# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')\n","\n","modeldir = \"drive/My Drive/Colab Notebooks/smaug/data/models\"\n","model.save_pretrained(modeldir)\n","print(os.listdir(modeldir))\n","# p = os.path.join(d, \"CDS_singlestrain_threeprime.pkl\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","['10-24-19_small', 'config.json', 'pytorch_model.bin']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"phBcIr86Aebe","colab_type":"code","colab":{}},"source":["# # TRIVIAL TASK: learn a single gene, should do perfectly\n","# # train model with single aa masked at a time ##### batch\n","# model.train()\n","\n","# batch_size = 2**5\n","\n","# # loss_mask = (torch.zeros(batch_size, max_position_embeddings)-1).long().to('cuda')\n","# optimizer.zero_grad()\n","# np.random.seed(2019)\n","# for i in range(10000):\n","# #     select_idx = np.random.randint(0, len(dtrain), batch_size)\n","# #     select_idx = np.random.randint(0, 1, batch_size)\n","#     select_idx = torch.zeros(batch_size).long() + 100\n","# #     print(select_idx)\n","# #     sys.exit()\n","\n","# #     print(batch_size)\n","# #     sys.exit()\n","# #     input_ids = dtrain[select_idx].unsqueeze(0)\n","#     input_ids = dtrain[select_idx]\n","    \n","    \n","#     outputs = model(input_ids, labels=input_ids)\n","#     loss, prediction_scores = outputs[:2]\n","    \n","#     loss.backward()\n","#     optimizer.step()\n","#     optimizer.zero_grad()\n","    \n","#     clear_output(wait=True)\n","#     for k in range(1, 10):\n","#         print(i, torch.argmax(prediction_scores[0,k-1]).item(), input_ids[0,k].item(), \"\\t\", loss.item())\n","# #     print()\n","    \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"os60No5hIIQy","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DuEevAU2Vjxz","colab_type":"code","outputId":"36ed3d42-3e32-4bab-b45a-e7b841ad50c6","executionInfo":{"status":"ok","timestamp":1572011094815,"user_tz":240,"elapsed":47832,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# evaluate the model using softmax proportion of correct label\n","model.eval()\n","\n","np.random.seed(4242424)\n","\n","maxsum = 0\n","softsum = 0\n","n_correct = 0\n","n_total = 0\n","for i in range(50):\n","    select_idx = np.random.randint(0,len(dvalid),1)[0]    \n","    input_ids = dvalid[select_idx].unsqueeze(0)\n","    # print(input_ids)\n","    \n","    for j in range(0, max_position_embeddings-1):\n","        tempval = 0\n","        tempval += input_ids[0, j+1].item()\n","#         print(tempval)\n","        if tempval != 0:\n","            logits = model(input_ids)[0][0,j]\n","            soft = torch.exp(logits)\n","            softproportion = (soft[tempval]/torch.sum(soft)).item() #######bug tempval not j\n","            softsum += softproportion\n","#             print(torch.sum(soft))\n","            maxsum += 1\n","\n","            pred = torch.argmax(logits).item()\n","            actual = tempval\n","            n_correct += pred==actual\n","            n_total +=1\n","#             if j ==5:\n","#                 sys.exit()\n","            \n","\n","correctness = softsum/maxsum\n","print(correctness)\n","\n","correctness_p = n_correct/n_total\n","print(correctness_p)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["0.1194689525090731\n","0.20205128205128206\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"012kPmDZVjwM","colab_type":"code","outputId":"7b9eadcb-9c03-4060-cb47-9b49b078f201","executionInfo":{"status":"ok","timestamp":1572010700459,"user_tz":240,"elapsed":98569,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# evaluate the model using softmax proportion of correct label, ON NOISE\n","model.eval()\n","\n","np.random.seed(4242424)\n","\n","maxsum = 0\n","softsum = 0\n","n_correct = 0\n","n_total = 0\n","for i in range(100):\n","#     select_idx = np.random.randint(0,len(dvalid),1)[0]    \n","#     input_ids = dvalid[select_idx].unsqueeze(0)\n","    noise = np.random.randint(1, 20, max_position_embeddings).reshape(1,-1)\n","    input_ids = torch.from_numpy(noise).to('cuda')\n","#     print(input_ids)\n","    \n","    for j in range(max_position_embeddings):\n","        tempval = 0\n","        tempval += input_ids[0, j].item()\n","        if tempval != 0:\n","            logits = model(input_ids)[0][0,j]\n","            soft = torch.exp(logits)\n","            softproportion = (soft[tempval]/torch.sum(soft)).item()\n","            softsum += softproportion\n","            maxsum += 1\n","\n","            pred = torch.argmax(logits).item()\n","            actual = tempval\n","            n_correct += pred==actual\n","            n_total +=1\n","            \n","\n","correctness = softsum/maxsum\n","print(correctness)\n","\n","correctness_p = n_correct/n_total\n","print(correctness_p)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["0.05510502388636814\n","0.0565\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SWYhjgeVVjuj","colab_type":"code","outputId":"3bfdfcf8-f34d-4598-c27d-5c7ac1bddc58","executionInfo":{"status":"ok","timestamp":1572010718367,"user_tz":240,"elapsed":3016,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# evaluate using model that just predicts most common amino acid\n","model.eval()\n","\n","np.random.seed(4242424)\n","\n","\n","maxsum = 0\n","softsum = 0\n","n_correct = 0\n","n_total = 0\n","for i in range(500):\n","    select_idx = np.random.randint(0,len(dvalid),1)[0]    \n","    input_ids = dvalid[select_idx].unsqueeze(0)\n","    \n","    for j in range(max_position_embeddings):\n","        tempval = 0\n","        tempval += input_ids[0, j].item()\n","        if tempval != 0:\n","            soft = torch.zeros(vocab_size)\n","            soft[1] += 1 ################\n","            softproportion = (soft[tempval]/torch.sum(soft)).item()\n","            softsum += softproportion\n","            maxsum += 1\n","\n","            pred = torch.argmax(soft).item()\n","\n","            actual = tempval\n","            n_correct += pred==actual\n","            n_total += 1\n","            \n","correctness = softsum/maxsum\n","print(correctness)\n","\n","correctness_p = n_correct/n_total\n","print(correctness_p)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["0.09955\n","0.09955\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M36vnpBJVjsu","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MC_TvK5RVjcA","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IY73upOVVjZu","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fH281QsnVjXH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g9O2DuEMHm3X","colab_type":"code","outputId":"33f7f727-46c2-4862-c0b8-3f54ae7afc50","executionInfo":{"status":"ok","timestamp":1571861136594,"user_tz":240,"elapsed":1767,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# evaluate model GPT2\n","model.eval()\n","\n","np.random.seed(424242)\n","\n","n_correct = 0\n","n_wrong = 0\n","for i in range(200):\n","    select_idx = np.random.randint(0,len(dvalid), 2)[0]    \n","    input_ids = dvalid[select_idx].unsqueeze(0)\n","    logits = model(input_ids, labels=input_ids)[1]\n","    prediction = torch.argmax(logits, 2)\n","#     print(logits.shape)\n","#     print(prediction)\n","#     print(input_ids)\n","    correct = torch.sum(prediction[0, 1:]==input_ids[0, 1:]).item()\n","    n_correct += correct # exclude first value because model is directionally causal\n","    n_wrong += (max_position_embeddings-1)-correct # max possible is max_position_embeddings-1\n","#     print(n_correct, n_wrong)\n","\n","print(n_correct/(n_correct+n_wrong))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.12\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A_oX0DI-LKew","colab_type":"code","outputId":"d11c0985-ff9f-47b5-c3c1-2f78f5aba3f5","executionInfo":{"status":"ok","timestamp":1571861141912,"user_tz":240,"elapsed":3760,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# evaluate model GPT2 ON NOISE, should be 0.05\n","model.eval()\n","\n","np.random.seed(42)\n","\n","n_correct = 0\n","n_wrong = 0\n","for i in range(1000):\n","    noise = np.random.randint(1, 20, max_position_embeddings).reshape(1,-1)\n","    input_ids = torch.from_numpy(noise).to('cuda')\n","    \n","    logits = model(input_ids, labels=input_ids)[1]\n","    prediction = torch.argmax(logits, 2)\n","#     print(prediction)\n","#     print(input_ids)\n","    correct = torch.sum(prediction[0, 1:]==input_ids[0, 1:]).item()\n","    n_correct += correct # exclude first value because model is directionally causal\n","    n_wrong += (max_position_embeddings-1)-correct # max possible score is max_position_embeddings-1\n","#     print(n_correct, n_wrong)\n","\n","print(n_correct/(n_correct+n_wrong))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.05333333333333334\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sHJLGmpjsOQo","colab_type":"code","outputId":"e7181a2b-b358-409a-b225-f89b41397d17","executionInfo":{"status":"ok","timestamp":1571859271202,"user_tz":240,"elapsed":1993,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# # evaluate model\n","# model.eval()\n","\n","# np.random.seed(424242)\n","# predseq = []\n","# actualseq = []\n","# for i in range(20):\n","#     select_idx = np.random.randint(0,len(dvalid),1)[0]    \n","#     input_ids = dvalid[select_idx].unsqueeze(0)\n","\n","    \n","# #     for j in range(max_position_embeddings):\n","#     for j in range(10):\n","\n","#         tempval = 0\n","#         tempval += input_ids[0, j].item()\n","#         if tempval != 0:\n","#             input_ids[0, j] = vocab_size-1 # mask label is the highest vocab number, never present in data\n","#             predicted_aa = torch.argmax(model(input_ids)[0][0,j]).item() # TODO mask padding 0's for attention\n","# #             print(model(input_ids)[0][0,j])\n","# #             print(input_ids)\n","# #             sys.exit()\n","#             input_ids[0,j] = tempval # set masked value back to original value\n","# #             print(model(input_ids)[0][0,j])\n","#             predseq.append(predicted_aa)\n","#             actualseq.append(tempval)\n","#             print(i, predicted_aa,tempval)\n","\n","# n_correct = 0\n","# n_wrong = 0\n","# for i, aa in enumerate(predseq):\n","#     if aa == actualseq[i]:\n","#         n_correct += 1\n","#     else:\n","#         n_wrong += 1\n","# print(n_correct/(n_correct+n_wrong))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0 11 10\n","0 9 20\n","0 4 9\n","0 4 7\n","0 1 1\n","0 12 7\n","0 4 7\n","0 8 1\n","0 6 1\n","0 12 1\n","1 11 10\n","1 9 18\n","1 4 1\n","1 11 19\n","1 1 12\n","1 12 7\n","1 4 9\n","1 8 19\n","1 6 11\n","1 12 3\n","2 11 11\n","2 8 6\n","2 4 14\n","2 11 13\n","2 1 14\n","2 12 10\n","2 4 9\n","2 8 6\n","2 6 8\n","2 12 19\n","3 11 14\n","3 8 10\n","3 4 2\n","3 11 1\n","3 1 13\n","3 12 8\n","3 4 9\n","3 8 19\n","3 6 11\n","3 12 19\n","4 11 19\n","4 8 5\n","4 4 15\n","4 4 17\n","4 1 5\n","4 12 16\n","4 4 7\n","4 8 19\n","4 6 6\n","4 12 4\n","5 11 8\n","5 8 2\n","5 4 9\n","5 11 3\n","5 1 2\n","5 12 7\n","5 4 5\n","5 8 17\n","5 6 6\n","5 12 1\n","6 11 20\n","6 8 8\n","6 4 7\n","6 11 4\n","6 1 1\n","6 12 18\n","6 4 14\n","6 8 2\n","6 6 6\n","6 12 3\n","7 11 18\n","7 8 6\n","7 4 9\n","7 4 10\n","7 1 4\n","7 12 2\n","7 4 11\n","7 8 14\n","7 6 6\n","7 12 7\n","8 11 6\n","8 9 15\n","8 4 10\n","8 4 1\n","8 1 6\n","8 12 6\n","8 4 3\n","8 8 2\n","8 6 4\n","8 12 3\n","9 11 10\n","9 9 1\n","9 4 10\n","9 11 9\n","9 1 10\n","9 12 17\n","9 4 16\n","9 8 8\n","9 6 6\n","9 12 10\n","10 11 19\n","10 8 17\n","10 4 3\n","10 4 14\n","10 1 9\n","10 12 2\n","10 4 2\n","10 8 14\n","10 6 9\n","10 12 18\n","11 11 19\n","11 8 6\n","11 4 15\n","11 4 3\n","11 1 6\n","11 12 6\n","11 4 17\n","11 8 6\n","11 6 6\n","11 12 14\n","12 11 6\n","12 9 8\n","12 4 16\n","12 4 1\n","12 1 19\n","12 12 13\n","12 4 3\n","12 8 8\n","12 6 6\n","12 12 16\n","13 11 1\n","13 8 18\n","13 4 17\n","13 11 14\n","13 1 1\n","13 12 14\n","13 4 10\n","13 8 1\n","13 6 2\n","13 12 14\n","14 11 15\n","14 8 1\n","14 4 6\n","14 4 7\n","14 1 4\n","14 12 2\n","14 4 15\n","14 8 7\n","14 6 19\n","14 12 11\n","15 11 6\n","15 9 20\n","15 4 6\n","15 4 2\n","15 1 2\n","15 12 19\n","15 12 1\n","15 8 19\n","15 6 2\n","15 12 12\n","16 11 15\n","16 8 18\n","16 4 2\n","16 11 10\n","16 1 11\n","16 12 9\n","16 4 10\n","16 8 12\n","16 6 6\n","16 12 14\n","17 11 10\n","17 9 18\n","17 4 6\n","17 4 19\n","17 1 8\n","17 12 6\n","17 4 17\n","17 8 1\n","17 6 9\n","17 12 19\n","18 11 5\n","18 9 1\n","18 4 19\n","18 4 10\n","18 1 6\n","18 12 15\n","18 4 6\n","18 8 8\n","18 6 11\n","18 12 11\n","19 11 19\n","19 8 6\n","19 4 10\n","19 4 15\n","19 1 1\n","19 12 2\n","19 4 7\n","19 8 7\n","19 6 1\n","19 12 8\n","0.09\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ofUqreTNAdS3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pNzBaw3IAdE7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qsYYknW6rZcs","colab_type":"code","colab":{}},"source":["    \n","    \n","    \n","\n","#     for j in range(max_position_embeddings):\n","#         tempval = torch.zeros(batch_size).long()\n","\n","#         for k in range(batch_size):\n","#             tempval[k] = input_ids[k, j].item()\n","        \n","#         optimizer.zero_grad()\n","\n","# #         loss_mask[:, j] = tempval # calculate loss based only on masked amino acid\n","      \n","# #         input_ids[:, j] = vocab_size-1 # mask label is the highest vocab number, never present in data\n","\n","#         outputs = model(input_ids, labels=) #TODO mask padding 0's for attention\n","# #         print(outputs)\n","\n","#         loss, prediction_scores = outputs[:2]\n","#         print(outputs.shape)\n","#         sys.exit()\n","# #         loss, prediction_scores = outputs\n","\n","        \n","#         for k in range(batch_size):\n","#             print(i, torch.argmax(prediction_scores[k,j]).item(), loss_mask[k,j].item(), \"\\t\", loss.item())\n","#         print()\n","        \n","#         loss.backward()\n","#         optimizer.step()\n","\n","#         for k in range(batch_size):\n","#             input_ids[k, j] = tempval[k] # set masked value back to original value\n","#             loss_mask[k, j] = -1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W7HkebPG55YS","colab_type":"code","colab":{}},"source":["# # train model with single aa masked at a time\n","# model.train()\n","# loss_mask = (torch.zeros(max_position_embeddings)-1).long().to('cuda')\n","\n","# np.random.seed(2019)\n","# for i in range(1000):\n","#     select_idx = np.random.randint(0,len(dtrain),1)[0]    \n","#     input_ids = dtrain[select_idx].unsqueeze(0)\n","\n","#     for j in range(max_position_embeddings):\n","#         tempval = 0\n","#         tempval += input_ids[0, j].item()\n","#         if tempval != 0:\n","#             optimizer.zero_grad()\n","\n","#             loss_mask[j] = tempval # calculate loss based only on masked amino acid\n","#             input_ids[0, j] = vocab_size-1 # mask label is the highest vocab number, never present in data\n","\n","#             outputs = model(input_ids, masked_lm_labels=loss_mask) #TODO mask padding 0's for attention\n","#             loss, prediction_scores = outputs[:2]\n","#             print(i, torch.argmax(prediction_scores[0,j]).item(), loss.item())\n","#             loss.backward()\n","#             optimizer.step()\n","\n","#             input_ids[0,j] = tempval # set masked value back to original value\n","#             loss_mask[j] = -1\n","\n","# #             if j==10:\n","# #                 break\n","#         else:\n","#             break # stop training at end of protein sequence\n","\n","# #     break"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PKPz_z3Z55YU","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4JIPb1Sk55YW","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DOrHuRH_55YY","colab_type":"code","outputId":"2c3668c5-7748-4179-80b2-0c68cf316f98","executionInfo":{"status":"ok","timestamp":1571847057385,"user_tz":240,"elapsed":343,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":[""],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([1, 100, 22])\n","1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z2RpZdto55Ya","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NRKlpDWC55Yb","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"19Smkiji55Yd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BtmrJyUJ55Ye","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QwRPG3cX55Yg","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oThB3Osi55Yi","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"laiAuExQ55Yn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r7xT6bIj55Yo","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IsWkzh0t55Yq","colab_type":"code","colab":{}},"source":["def evaluate(model, data):\n","    model.eval()\n","    acc_list = []\n","    for d in data:\n","        outputs = model(d.unsqueeze(0), masked_lm_labels=d.unsqueeze(0))\n","        loss, prediction_scores = outputs[:2]\n","        \n","        predicted_index = torch.argmax(prediction_scores, dim=2)\n","        n_correct = torch.sum(predicted_index==d).item()\n","#         n_possible = torch.sum(d!=0).item()\n","        n_possible = len(predicted_index[0])\n","        acc = n_correct/n_possible\n","        acc_list.append(acc)\n","        \n","    return(np.mean(acc_list))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-0tWGotR55Yy","colab_type":"code","colab":{}},"source":["# train model\n","batch_size = 1\n","\n","optimizer = optim.SGD(model.parameters(), lr=0.01)#, momentum=args.momentum)\n","# optimizer = optim.AdamW(model.parameters())\n","_max_select = len(dtrain)\n","\n","\n","# single step to non-zero weights\n","optimizer.zero_grad()\n","select_idx = np.random.randint(0, _max_select, batch_size)\n","outputs = model(dtrain[select_idx], masked_lm_labels=dtrain[select_idx])\n","loss, prediction_scores = outputs[:2]\n","loss.backward()\n","optimizer.step()\n","\n","# # evaluate before training\n","# acc_train = evaluate(model, dtrain)\n","# acc_valid = evaluate(model, dvalid)\n","# print(acc_train)\n","# print(acc_valid)\n","\n","\n","# train\n","model.train()\n","np.random.seed(2019)\n","for i in range(100):\n","    optimizer.zero_grad()\n","    select_idx = np.random.randint(0, _max_select, batch_size)\n","    input_ids = tokens_tensor[select_idx]\n","    outputs = model(input_ids, masked_lm_labels=input_ids)\n","    loss, prediction_scores = outputs[:2]\n","    print(i, loss.item())\n","    loss.backward()\n","    optimizer.step()\n","    \n","#     loss.backward(retain_graph=True)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EH1AQEIR55Y0","colab_type":"code","colab":{}},"source":["# after training\n","acc_train = evaluate(model, dtrain)\n","acc_valid = evaluate(model, dvalid)\n","print(acc_train)\n","print(acc_valid)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cFBbjL0U55Y2","colab_type":"code","colab":{}},"source":["model.eval()\n","outputs = model(dvalid[0].unsqueeze(0), masked_lm_labels=dvalid[0].unsqueeze(0))\n","loss, prediction_scores = outputs[:2]\n","\n","predicted_index = torch.argmax(prediction_scores, dim=2)\n","print(predicted_index)\n","print(dvalid[0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5-S5jD8b55Y3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MrUL2vPe55Y5","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UM8u0ry555Y6","colab_type":"code","colab":{}},"source":["\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tJJWFg6E55Y8","colab_type":"code","colab":{}},"source":["# debug\n","model.train()\n","optimizer = optim.SGD(model.parameters(), lr=0.01)#, momentum=args.momentum)\n","for i in range(10):\n","    optimizer.zero_grad()\n","#     select_idx = 1\n","#     input_ids = tokens_tensor[select_idx].unsqueeze(0)\n","#     input_ids = tokens_tensor[0:3]\n","    input_ids = dtrain[0].unsqueeze(0)\n","\n","    outputs = model(input_ids, masked_lm_labels=input_ids)\n","    loss, prediction_scores = outputs[:2]\n","    print(i, loss.item())\n","    loss.backward()\n","    optimizer.step()\n","    \n","#     loss.backward(retain_graph=True)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KRXZhMQl55Y-","colab_type":"code","colab":{}},"source":["model.eval()\n","select_idx = 5\n","input_ids = tokens_tensor[select_idx].unsqueeze(0)\n","outputs = model(input_ids, masked_lm_labels=input_ids)\n","loss, prediction_scores = outputs[:2]\n","\n","predicted_index = torch.argmax(prediction_scores, dim=2)\n","a = evaluate(model, tokens_tensor[select_idx].unsqueeze(0))\n","print(a)\n","# print(predicted_index.shape)\n","print(predicted_index)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rPNcl53N55ZA","colab_type":"code","colab":{}},"source":["# evaluate on random data to ensure accuracy metric works\n","model.eval()\n","\n","np.random.seed(2019)\n","noise = np.random.randint(1, 10, 512).reshape(1,-1)\n","input_ids = torch.from_numpy(noise).to('cuda')\n","\n","outputs = model(input_ids, masked_lm_labels=input_ids)\n","loss, prediction_scores = outputs[:2]\n","\n","predicted_index = torch.argmax(prediction_scores, dim=2)\n","a = evaluate(model, tokens_tensor[select_idx].unsqueeze(0))\n","print(a)\n","# print(predicted_index.shape)\n","print(input_ids)\n","print(predicted_index)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Vnu2wrN55ZC","colab_type":"code","colab":{}},"source":["# fix forward mask\n","model.eval()\n","\n","np.random.seed(2019)\n","noise = np.random.randint(1, 10, 512).reshape(1,-1)\n","input_ids = torch.from_numpy(noise).to('cuda')\n","input_ids[0,0] = -inf\n","\n","attention_mask = torch.from_numpy(np.ones(512).reshape(1,-1)).float().to('cuda')\n","attention_mask[0,0] = 0\n","# print(attention_mask)\n","\n","token_type_ids = torch.from_numpy(np.zeros(512).reshape(1,-1)).long().to('cuda')\n","\n","outputs = model(input_ids, masked_lm_labels=input_ids)\n","loss, prediction_scores = outputs[:2]\n","\n","predicted_index = torch.argmax(prediction_scores, dim=2)\n","a = evaluate(model, tokens_tensor[select_idx].unsqueeze(0))\n","print(a)\n","# print(predicted_index.shape)\n","print(input_ids)\n","print(predicted_index)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pJau2_9b55ZE","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XT2JkPMN55ZG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6j2KIu7f55ZI","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7Z0_Jgm55ZK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ASXO5gOa55ZN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PSU4rrdO55ZP","colab_type":"code","colab":{}},"source":["del model\n","torch.cuda.empty_cache()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aI-t2Rs555ZU","colab_type":"code","colab":{}},"source":["# train model\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","def train_epoch(epoch, args, model, device, data_loader, optimizer):\n","    model.train()  # set to training mode, disappointingly does not actually train the model \n","    pid = os.getpid()\n","    for batch_idx, (data, target) in enumerate(data_loader):\n","        optimizer.zero_grad()\n","        output = model(data.to(device))\n","        loss = F.nll_loss(output, target.to(device))\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % args.log_interval == 0:\n","            print('{}\\tTrain Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                pid, epoch, batch_idx * len(data), len(data_loader.dataset),\n","                100. * batch_idx / len(data_loader), loss.item()))\n","            \n","optimizer = optim.SGD(model.parameters(), lr=0.01)#, momentum=args.momentum)\n","optimizer.zero_grad()\n","# output = model(tokens_tensor)\n","# loss = F.nll_loss(output, target.to('cuda'))\n","print([x for x in model.parameters()])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PoBBBQeO55ZV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iiY2TVZI55ZW","colab_type":"code","colab":{}},"source":["from transformers import BertTokenizer, BertModel, BertForMaskedLM\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","# model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n","model = BertForMaskedLM(config)\n","\n","input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\")).unsqueeze(0)  # Batch size 1\n","outputs = model(input_ids, masked_lm_labels=input_ids)\n","loss, prediction_scores = outputs[:2]\n","print(loss)\n","print(prediction_scores)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gxSiqrMs55ZY","colab_type":"code","colab":{}},"source":["print(input_ids.shape)\n","print(tokens_tensor[0].unsqueeze(0).shape)\n","print(tokens_tensor[0:2].shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DYID7shz55ZZ","colab_type":"code","colab":{}},"source":["from transformers import BertTokenizer, BertModel, BertForMaskedLM\n","\n","# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","# model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n","model = BertForMaskedLM(config)\n","model.to('cuda')\n","\n","# input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\")).unsqueeze(0)  # Batch size 1\n","# input_ids = tokens_tensor[0].unsqueeze(0)\n","input_ids = tokens_tensor[0:2]\n","\n","outputs = model(input_ids, masked_lm_labels=input_ids)\n","loss, prediction_scores = outputs[:2]\n","print(loss)\n","print(prediction_scores.shape)\n","\n","for i in range(2):\n","    input_ids = tokens_tensor[0:2]\n","    outputs = model(input_ids, masked_lm_labels=input_ids)\n","    loss, prediction_scores = outputs[:2]\n","    loss.backward()\n","    print(loss)\n","    print(prediction_scores.shape)\n","#     loss.backward(retain_graph=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XfFqO-6r55Zd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tGFpnqCO55Zh","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EXV_Oiij55Zi","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qpPPk-sf55Zl","colab_type":"code","colab":{}},"source":["import torch\n","from transformers import BertTokenizer, BertModel, BertForMaskedLM\n","\n","# OPTIONAL: if you want to have more information on what's happening under the hood, activate the logger as follows\n","# import logging\n","# logging.basicConfig(level=logging.INFO)\n","# logging.basicConfig(level=logging.NONE)\n","\n","\n","# Load pre-trained model tokenizer (vocabulary)\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# Tokenize input\n","text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n","tokenized_text = tokenizer.tokenize(text)\n","\n","# Mask a token that we will try to predict back with `BertForMaskedLM`\n","# masked_index = 8\n","# tokenized_text[masked_index] = '[MASK]'\n","\n","# Convert token to vocabulary indices\n","indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n","print(indexed_tokens)\n","# Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n","segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n","\n","# Convert inputs to PyTorch tensors\n","tokens_tensor = torch.tensor([indexed_tokens])\n","segments_tensors = torch.tensor([segments_ids])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"evUYO0la55Zn","colab_type":"code","colab":{}},"source":["# Load pre-trained model (weights)\n","model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n","model.eval()\n","\n","# If you have a GPU, put everything on cuda\n","tokens_tensor = tokens_tensor.to('cuda')\n","# segments_tensors = segments_tensors.to('cuda')\n","model.to('cuda')\n","\n","# Predict all tokens\n","with torch.no_grad():\n","#     outputs = model(tokens_tensor, token_type_ids=segments_tensors)\n","    outputs = model(tokens_tensor)\n","\n","    predictions = outputs[0]\n","\n","# confirm we were able to predict 'henson'\n","predicted_index = torch.argmax(predictions[0, masked_index]).item()\n","predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n","print(predicted_token)\n","\n","predicted_index = torch.argmax(predictions[0, 11]).item()\n","predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n","print(predicted_token)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PX9CA45w55Zq","colab_type":"code","colab":{}},"source":["for i in range(len(indexed_tokens)):\n","    predicted_index = torch.argmax(predictions[0, i]).item()\n","    predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n","    print(predicted_token)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MQ04k5P255Zr","colab_type":"code","colab":{}},"source":["predicted_token = tokenizer.convert_ids_to_tokens([103])[0]\n","print(predicted_token)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tThRe7ba55Zt","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gz4USnvY55Zv","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wz46wnbx55Zw","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KrqNGCF_55Zx","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tUsU5Ge655Zz","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dDVX4TcF55Z0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5L_l4eMA55Z1","colab_type":"code","colab":{}},"source":["import logging\n","logging.basicConfig(level=logging.INFO)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mH73ih9855Z2","colab_type":"code","colab":{}},"source":["# example tokenization\n","from transformers import BertTokenizer, BertModel, BertForMaskedLM\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n","tokenized_text = tokenizer.tokenize(text)\n","print(tokenized_text)\n","\n","masked_index = 8\n","tokenized_text[masked_index] = '[MASK]'\n","print(tokenized_text)\n","\n","indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n","tokens_tensor = torch.tensor([indexed_tokens])\n","print(tokens_tensor)\n","print(tokens_tensor.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YITbbsNm55Z3","colab_type":"code","colab":{}},"source":["# Load pre-trained model (weights)\n","model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n","model.eval()\n","\n","# If you have a GPU, put everything on cuda\n","tokens_tensor = tokens_tensor.to('cuda')\n","# segments_tensors = segments_tensors.to('cuda')\n","model.to('cuda')\n","\n","# Predict all tokens\n","with torch.no_grad():\n","#     outputs = model(tokens_tensor, token_type_ids=segments_tensors)\n","    outputs = model(tokens_tensor)\n","    predictions = outputs[0]\n","\n","# confirm we were able to predict 'henson'\n","predicted_index = torch.argmax(predictions[0, masked_index]).item()\n","predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n","print(predicted_token)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fd21GWBz55Z6","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ezPuox855Z8","colab_type":"code","outputId":"fab38698-1d71-45cb-ec06-f869068dd13b","executionInfo":{"status":"ok","timestamp":1571673957351,"user_tz":240,"elapsed":283731,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# GPT-2\n","\n","import torch\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","\n","# Load pre-trained model tokenizer (vocabulary)\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2-large')\n","\n","# Load pre-trained model (weights)\n","model = GPT2LMHeadModel.from_pretrained('gpt2-large')\n","\n","\n","# Set the model in evaluation mode to deactivate the DropOut modules\n","# This is IMPORTANT to have reproducible results during evaluation!\n","model.eval()\n","model.to('cuda')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 1042301/1042301 [00:01<00:00, 937069.71B/s]\n","100%|██████████| 456318/456318 [00:00<00:00, 500226.97B/s]\n","100%|██████████| 529/529 [00:00<00:00, 227614.57B/s]\n","100%|██████████| 3247202234/3247202234 [03:41<00:00, 14645396.05B/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(50257, 1280)\n","    (wpe): Embedding(1024, 1280)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (12): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (13): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (14): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (15): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (16): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (17): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (18): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (19): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (20): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (21): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (22): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (23): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (24): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (25): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (26): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (27): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (28): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (29): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (30): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (31): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (32): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (33): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (34): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (35): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=1280, out_features=50257, bias=False)\n",")"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"Fj4V8Z8255Z_","colab_type":"code","colab":{}},"source":["# original_text = \"Martin Steinegger is in Peru because he \"\n","# original_text = \"The real reason Steven keeps recruiting German postdocs is \"\n","# original_text = \"The secret to giving a fun and compelling Joint Lab Meeting presentation is \"\n","# original_text = \"UC Berkeley is\"\n","# original_text = \"Why did Donald Trump \"\n","# original_text = \"Finding genes is easy... The secret is \"\n","# original_text = \"Computational gene finding is easy, the problem is \"\n","# original_text = \"The future of Biomedical Engineering is \"\n","# original_text = \"The best way to describe how neural networks work is \"\n","original_text = \"Improving on state-of-the-art bacterial gene finding programs is hard, \"\n","\n","\n","text = original_text\n","for i in range(20): # not the best way to iterate, but it works\n","    if text[-1] != \".\":\n","        # Encode a text inputs\n","        indexed_tokens = tokenizer.encode(text)\n","\n","        # Convert indexed tokens in a PyTorch tensor\n","        tokens_tensor = torch.tensor([indexed_tokens])\n","\n","        # If you have a GPU, put everything on cuda\n","        tokens_tensor = tokens_tensor.to('cuda')\n","\n","        # Predict all tokens\n","        with torch.no_grad():\n","            outputs = model(tokens_tensor)\n","            predictions = outputs[0]\n","\n","        # get the predicted next sub-word (in our case, the word 'man')\n","        predicted_index = torch.argmax(predictions[0, -1, :]).item()\n","        predicted_text = tokenizer.decode(indexed_tokens + [predicted_index])\n","\n","        text = predicted_text"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GnlswbS155aA","colab_type":"code","outputId":"7ed70e38-64f6-4c01-861d-013d549c29bf","colab":{}},"source":["print(\"Original text:\\t\\t\", original_text)\n","print(\"Completed sentence:\\t\", predicted_text)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Original text:\t\t Improving on state-of-the-art bacterial gene finding programs is hard, \n","Completed sentence:\t Improving on state-of-the-art bacterial gene finding programs is hard, but it's not impossible.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AT2RmpXZ55aC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FFR-o-dr55aD","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KKSSFryL55aE","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aqxg6dGV55aF","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aUvkNFcZ55aH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vn9QworP55aI","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7br8_zL55aL","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0t_F1Fno55aL","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ru6wfCmi55aN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}