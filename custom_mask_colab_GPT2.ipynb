{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"custom_mask_colab_GPT2.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"03irV-C_6jpZ","colab_type":"code","colab":{}},"source":["!pip install transformers"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MTLDde1m6k_O","colab_type":"code","outputId":"ced7e7ba-2a3b-47bd-d1a3-df072ac63f03","executionInfo":{"status":"ok","timestamp":1572281532556,"user_tz":240,"elapsed":15240,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X3i73FlB55Xt","colab_type":"code","outputId":"f65f22c2-6ad4-4763-bdca-1574578a1088","executionInfo":{"status":"ok","timestamp":1572281535029,"user_tz":240,"elapsed":17224,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":63}},"source":["import os\n","import sys\n","import pickle\n","import torch\n","import numpy as np\n","import torch.optim as optim\n","# from transformers import BertConfig, BertModel, BertForMaskedLM\n","from transformers import GPT2Config, GPT2Model, GPT2LMHeadModel\n","\n","from IPython.display import clear_output\n","\n","# import matplotlib.pyplot as plt\n","# from transformers import *"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"kBbEF2Uc6lK5","colab_type":"code","outputId":"63a3f8eb-8a3c-49b4-dc62-c24f1f131ad3","executionInfo":{"status":"ok","timestamp":1572281535033,"user_tz":240,"elapsed":17051,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["d = \"drive/My Drive/Colab Notebooks/smaug/data/ecoli_MG1655\"\n","p = os.path.join(d, \"CDS_singlestrain_threeprime.pkl\")\n","print(os.listdir(d))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['CDS_singlestrain_threeprime.pkl', 'models', 'config.json', 'pytorch_model.bin']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cA49xxRjaakk","colab_type":"code","colab":{}},"source":["with open(p, 'rb') as f:\n","  CDS = pickle.load(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XXjv4EukaaiC","colab_type":"code","outputId":"dc6ea127-05c5-45b1-c954-252695bc3ef8","executionInfo":{"status":"ok","timestamp":1572281546673,"user_tz":240,"elapsed":27683,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["print(type(CDS))\n","print(len(CDS))\n","print(CDS[100])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<class 'list'>\n","9304394\n","HVSLLSVHAAVAVWRKKRQMYIDQYCVRGTKLTNAEKFVFTMYATVVGIKEDLMRVDASDINVSLIEQRRLNRIVDRRTMKNGDPSILIFDNAFIRELTVSDKSPYSRIWDENMRKLTEVSKNQAHLQCTFVMVLSFLLIAKM\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KVf-Zgp255X6","colab_type":"code","colab":{}},"source":["# lengths = [len(s) for s in CDS]\n","# meanlen = np.mean(lengths)\n","# medlen = np.median(lengths)\n","# minlen = np.min(lengths)\n","# maxlen = np.max(lengths)\n","# print(meanlen, medlen, minlen, maxlen)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EmIQPDvZ55X9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YMj7-AzZ55YA","colab_type":"code","colab":{}},"source":["# import logging\n","# logging.basicConfig(level=logging.INFO)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dvEYlPOb55YD","colab_type":"code","colab":{}},"source":["# # custom parameters for BERT model\n","# vocab_size = 12 # Vocabulary size of inputs_ids in BertModel. default=30522\n","# hidden_size = 768 # Size of the encoder layers and the pooler layer, default=768\n","# num_hidden_layers = 12 # Number of hidden layers in the Transformer encoder. default=12\n","# num_attention_heads = 12 # Number of attention heads for each attention layer in the Transformer encoder, default=12\n","# intermediate_size = 3072 # The size of the “intermediate” (i.e., feed-forward) layer in the Transformer encoder. default=3072\n","# hidden_act = \"gelu\" # The non-linear activation function (function or string) in the encoder and pooler. If string, “gelu”, “relu”, “swish” and “gelu_new” are supported. default=\"gelu\"\n","# hidden_dropout_prob = 0.1 # The dropout probabilitiy for all fully connected layers in the embeddings, encoder, and pooler. default=0.1\n","# attention_probs_dropout_prob = 0.1 # The dropout ratio for the attention probabilities. default=0.1\n","# max_position_embeddings = 512 # The maximum sequence length that this model might ever be used with. Typically set this to something large just in case (e.g., 512 or 1024 or 2048). default=512\n","# type_vocab_size = 2 # 1 # The vocabulary size of the token_type_ids passed into BertModel. default=2\n","# initializer_range = 0.02 # The sttdev of the truncated_normal_initializer for initializing all weight matrices. default=0.02\n","# layer_norm_eps = 1e-12 # The epsilon used by LayerNorm. default=1e-12\n","\n","\n","# config = BertConfig(vocab_size_or_config_json_file=vocab_size,\n","#                     hidden_size=hidden_size,\n","#                     num_hidden_layers=num_hidden_layers,\n","#                     num_attention_heads=num_attention_heads,\n","#                     intermediate_size=intermediate_size,\n","#                     hidden_act=hidden_act,\n","#                     hidden_dropout_prob=hidden_dropout_prob,\n","#                     attention_probs_dropout_prob=attention_probs_dropout_prob,\n","#                     max_position_embeddings=max_position_embeddings,\n","#                     type_vocab_size=type_vocab_size,\n","#                     initializer_range=initializer_range,\n","#                     layer_norm_eps=layer_norm_eps)\n","\n","# model = BertForMaskedLM(config)\n","\n","# print(model)\n","# model.to('cuda')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8Ra4nFr55YF","colab_type":"code","outputId":"ff3fe120-f596-4f36-b2f0-47a8fa0b4f5d","executionInfo":{"status":"ok","timestamp":1572281550198,"user_tz":240,"elapsed":28433,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# custom parameters for GPT2 model\n","vocab_size = 22\n","max_position_embeddings = 40 # 1024\n","n_ctw = max_position_embeddings # 1024\n","n_embd = 36 # 768\n","n_layer = 12 # 12\n","n_head = 12 # 12\n","\n","\n","config = GPT2Config(vocab_size_or_config_json_file=vocab_size,\n","                    n_positions=max_position_embeddings,\n","                    n_ctw=n_ctw,\n","                    n_embd=n_embd,\n","                    n_layer=n_layer,\n","                    n_head=n_head)\n","\n","model = GPT2LMHeadModel(config)\n","\n","print(model)\n","model.to('cuda')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(22, 36)\n","    (wpe): Embedding(40, 36)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=36, out_features=22, bias=False)\n",")\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(22, 36)\n","    (wpe): Embedding(40, 36)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): Block(\n","        (ln_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=36, out_features=22, bias=False)\n",")"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"rf0FLgnQ55YI","colab_type":"code","outputId":"85d4740a-fbbb-48f3-ea23-49c7e7b42ec5","executionInfo":{"status":"ok","timestamp":1572282323391,"user_tz":240,"elapsed":67298,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":155}},"source":["# encode data as GPU tensors\n","max_aa_seq_length = max_position_embeddings\n","\n","\n","def tokenize_aa_seq_murphy10(aa_seq):\n","    table = {\"L\":1,\n","             \"V\":1,\n","             \"I\":1,\n","             \"M\":1,\n","             \"C\":2,\n","             \"A\":3,\n","             \"G\":4,\n","             \"S\":5,\n","             \"T\":5,\n","             \"P\":6,\n","             \"F\":7,\n","             \"Y\":7,\n","             \"W\":7,\n","             \"E\":8,\n","             \"D\":8,\n","             \"N\":8,\n","             \"Q\":8,\n","             \"K\":9,\n","             \"R\":9,\n","             \"H\":10,\n","             \"X\":0, # get rid of those\n","             \"B\":0,\n","             \"*\":0}\n","    tokenized = [table[aa] for aa in aa_seq]\n","    return tokenized\n","\n","def tokenize_aa_seq(aa_seq):\n","    table = {\"L\":1,\n","             \"V\":2,\n","             \"I\":3,\n","             \"M\":4,\n","             \"C\":5,\n","             \"A\":6,\n","             \"G\":7,\n","             \"S\":8,\n","             \"T\":9,\n","             \"P\":10,\n","             \"F\":11,\n","             \"Y\":12,\n","             \"W\":13,\n","             \"E\":14,\n","             \"D\":15,\n","             \"N\":16,\n","             \"Q\":17,\n","             \"K\":18,\n","             \"R\":19,\n","             \"H\":20,\n","             \"X\":0, # get rid of those\n","             \"B\":0,\n","             \"*\":0}\n","    tokenized = [table[aa] for aa in aa_seq]\n","    return tokenized\n","\n","# tokens = [tokenize_aa_seq_murphy10(seq) for seq in CDS[:1000]] ######################################\n","foo = 0\n","offset = 100000\n","tokens = [tokenize_aa_seq(seq) for seq in CDS[foo:foo+offset]] ######################################\n","\n","tokens_tensor = torch.zeros(len(tokens), max_aa_seq_length, dtype=torch.long)\n","for i in range(len(tokens)):\n","    l = len(tokens[i]) # scuff way to ensure fit in tensor, TODO build correctly sized data set and split into train test\n","    if l > max_aa_seq_length:\n","        l = max_aa_seq_length\n","    for j in range(l):\n","        tokens_tensor[i][j] += tokens[i][j]\n","\n","tokens_tensor = tokens_tensor.to('cuda')\n","\n","print(tokens_tensor)\n","print(tokens_tensor.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[18,  1,  4,  ...,  6, 11,  8],\n","        [ 6, 17,  6,  ..., 11,  5,  7],\n","        [15, 19,  1,  ..., 10, 14, 20],\n","        ...,\n","        [15, 18,  6,  ..., 11, 15, 18],\n","        [18, 14, 14,  ...,  3, 14,  9],\n","        [ 6, 16,  6,  ...,  3,  8,  5]], device='cuda:0')\n","torch.Size([100000, 40])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zlHdsHkb55YM","colab_type":"code","outputId":"fb416ea5-457b-4503-fd64-2eb957424c77","executionInfo":{"status":"ok","timestamp":1572282323393,"user_tz":240,"elapsed":64954,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["dtrain = tokens_tensor[:int(0.8*len(tokens_tensor))] #TODO do an actual random selection on better data\n","dvalid = tokens_tensor[int(0.8*len(tokens_tensor)):]\n","print(len(dtrain))\n","print(len(dvalid))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["80000\n","20000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fXThUjamEcFX","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KUuZzFiD55YQ","colab_type":"code","colab":{}},"source":["# optimizer = optim.SGD(model.parameters(), lr=0.0001)#, momentum=args.momentum)\n","optimizer = optim.AdamW(model.parameters())\n","# optimizer = optim.Adam(model.parameters())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fnFVcaYf2D6t","colab_type":"code","colab":{}},"source":["def savemodel():\n","    # save model\n","    # Load the Drive helper and mount\n","    from google.colab import drive\n","\n","    # This will prompt for authorization.\n","    drive.mount('/content/drive')\n","\n","    modeldir = \"drive/My Drive/Colab Notebooks/smaug/data/models\"\n","    model.save_pretrained(modeldir)\n","    print(os.listdir(modeldir))\n","    # p = os.path.join(d, \"CDS_singlestrain_threeprime.pkl\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fUCw7GIA9vDL","colab_type":"code","outputId":"c1351934-c3f1-401e-9e6f-6ce8a12be0c4","executionInfo":{"status":"error","timestamp":1572011355530,"user_tz":240,"elapsed":366,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":189}},"source":["# train model with single aa masked at a time ##### batch\n","model.train()\n","\n","batch_size = 2**10\n","\n","optimizer.zero_grad()\n","np.random.seed(42424)\n","for i in range(100000):\n","    if i%500==10:\n","        savemodel()\n","    optimizer.zero_grad()\n","\n","    select_idx = np.random.randint(0, len(dtrain), batch_size)\n","\n","#     input_ids = dtrain[select_idx].unsqueeze(0) # singleton\n","    input_ids = dtrain[select_idx]\n","    \n","    \n","    outputs = model(input_ids, labels=input_ids)\n","    loss, prediction_scores = outputs[:2]\n","    \n","    loss.backward()\n","    optimizer.step()\n","    \n","    clear_output(wait=True)\n","    for k in range(0, 10):\n","#         print(i, torch.argmax(prediction_scores[0,k-1]).item(), input_ids[0,k].item(), \"\\t\", loss.item()) #TODO figure out why GPT2 only offsets sometimes\n","        print(i, \"\\t\", torch.argmax(prediction_scores[0,k-1]).item(), \"\\t\", input_ids[0,k].item(), \"\\t\", loss.item())\n","#         print(prediction_scores[0])\n","    \n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["779 \t 6 \t 18 \t 2.7642195224761963\n","779 \t 18 \t 1 \t 2.7642195224761963\n","779 \t 1 \t 11 \t 2.7642195224761963\n","779 \t 1 \t 7 \t 2.7642195224761963\n","779 \t 6 \t 9 \t 2.7642195224761963\n","779 \t 1 \t 6 \t 2.7642195224761963\n","779 \t 1 \t 5 \t 2.7642195224761963\n","779 \t 6 \t 16 \t 2.7642195224761963\n","779 \t 1 \t 6 \t 2.7642195224761963\n","779 \t 1 \t 4 \t 2.7642195224761963\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7CIuq8j7TYz4","colab_type":"code","colab":{}},"source":["# save model\n","# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')\n","\n","modeldir = \"drive/My Drive/Colab Notebooks/smaug/data/models\"\n","model.save_pretrained(modeldir)\n","print(os.listdir(modeldir))\n","# p = os.path.join(d, \"CDS_singlestrain_threeprime.pkl\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ult7ZQ9EOAaM","colab_type":"code","outputId":"70e749ea-6584-486d-a0dd-57339167d50c","executionInfo":{"status":"ok","timestamp":1572281571777,"user_tz":240,"elapsed":756,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# load model\n","# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')\n","\n","# modeldir = \"drive/My Drive/Colab Notebooks/smaug/data/models\"\n","modeldir = \"drive/My Drive/Colab Notebooks/smaug/data/models/10-25-19_morning_20\"\n","\n","model = GPT2LMHeadModel.from_pretrained(modeldir).to('cuda')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"phBcIr86Aebe","colab_type":"code","colab":{}},"source":["# # TRIVIAL TASK: learn a single gene, should do perfectly\n","# # train model with single aa masked at a time ##### batch\n","# model.train()\n","\n","# batch_size = 2**5\n","\n","# # loss_mask = (torch.zeros(batch_size, max_position_embeddings)-1).long().to('cuda')\n","# optimizer.zero_grad()\n","# np.random.seed(2019)\n","# for i in range(10000):\n","# #     select_idx = np.random.randint(0, len(dtrain), batch_size)\n","# #     select_idx = np.random.randint(0, 1, batch_size)\n","#     select_idx = torch.zeros(batch_size).long() + 100\n","# #     print(select_idx)\n","# #     sys.exit()\n","\n","# #     print(batch_size)\n","# #     sys.exit()\n","# #     input_ids = dtrain[select_idx].unsqueeze(0)\n","#     input_ids = dtrain[select_idx]\n","    \n","    \n","#     outputs = model(input_ids, labels=input_ids)\n","#     loss, prediction_scores = outputs[:2]\n","    \n","#     loss.backward()\n","#     optimizer.step()\n","#     optimizer.zero_grad()\n","    \n","#     clear_output(wait=True)\n","#     for k in range(1, 10):\n","#         print(i, torch.argmax(prediction_scores[0,k-1]).item(), input_ids[0,k].item(), \"\\t\", loss.item())\n","# #     print()\n","    \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"os60No5hIIQy","colab_type":"code","outputId":"9e220738-7fb7-4d0b-a4a1-8c23e26212b1","executionInfo":{"status":"ok","timestamp":1572283803942,"user_tz":240,"elapsed":3361,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# evaluate the model using softmax proportion of correct label, batch\n","model.eval()\n","\n","np.random.seed(4242424)\n","\n","maxsum = 0\n","softsum = 0\n","n_correct = 0\n","n_total = 0\n","\n","n_test = 1000\n","\n","select_idx = np.random.randint(0,len(dvalid),n_test)\n","input_ids = dvalid[select_idx]\n","\n","\n","logits = model(input_ids)[0]\n","soft = torch.exp(logits)\n","softsum = torch.sum(soft, axis=2).view(len(soft),-1,1)\n","softproportion = soft/softsum\n","\n","softcorrect = 0\n","for i in range(input_ids.shape[0]):\n","  for j in range(input_ids.shape[1] - 1): # remember prediction offset by 1\n","    softcorrect += softproportion[i, j, input_ids[i,j+1]]\n","softcorrect = softcorrect.item()\n","\n","predval = torch.roll(torch.argmax(softproportion, axis=2), 1) # remember prediction offset by 1\n","correctmask = predval == input_ids[:] # why no offset here?\n","hardcorrect = torch.sum(correctmask).item()\n","totalcorrect = logits.shape[0]*logits.shape[1]\n","\n","softproportion = softcorrect/totalcorrect\n","hardproportion = hardcorrect/totalcorrect\n","\n","# print(input_ids.shape)\n","# print(logits.shape)\n","# print(soft.shape)\n","# print(softsum.shape)\n","# print(softproportion.shape)\n","# # print(torch.sum(softproportion, axis=2))\n","# print(predval.shape)\n","# print(softcorrect)\n","# print(hardcorrect)\n","# print(totalcorrect)\n","print(softproportion)\n","print(hardproportion)\n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.125308935546875\n","0.196575\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DuEevAU2Vjxz","colab_type":"code","outputId":"29e369ee-8ddd-4eb0-878b-6cc8e83f8555","executionInfo":{"status":"ok","timestamp":1572282674710,"user_tz":240,"elapsed":86626,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# evaluate the model using softmax proportion of correct label\n","model.eval()\n","\n","np.random.seed(4242424)\n","\n","maxsum = 0\n","softsum = 0\n","n_correct = 0\n","n_total = 0\n","for i in range(100):\n","    select_idx = np.random.randint(0,len(dvalid),1)[0]    \n","    input_ids = dvalid[select_idx].unsqueeze(0)\n","    # print(input_ids)\n","    \n","    for j in range(0, max_position_embeddings-1):\n","        tempval = 0\n","        tempval += input_ids[0, j+1].item()\n","#         print(tempval)\n","        if tempval != 0:\n","            logits = model(input_ids)[0][0,j]\n","            soft = torch.exp(logits)\n","            softproportion = (soft[tempval]/torch.sum(soft)).item() #######bug tempval not j\n","            softsum += softproportion\n","#             print(torch.sum(soft))\n","            maxsum += 1\n","\n","            pred = torch.argmax(logits).item()\n","            actual = tempval\n","            n_correct += pred==actual\n","            n_total +=1\n","#             if j ==5:\n","#                 sys.exit()\n","            \n","\n","correctness = softsum/maxsum\n","print(correctness)\n","\n","correctness_p = n_correct/n_total\n","print(correctness_p)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.12334426409517152\n","0.19794871794871796\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"012kPmDZVjwM","colab_type":"code","outputId":"f0ab360e-ecc9-4235-d750-1908613cbd99","executionInfo":{"status":"ok","timestamp":1572282565290,"user_tz":240,"elapsed":89121,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# evaluate the model using softmax proportion of correct label, ON NOISE\n","model.eval()\n","\n","np.random.seed(4242424)\n","\n","maxsum = 0\n","softsum = 0\n","n_correct = 0\n","n_total = 0\n","for i in range(100):\n","#     select_idx = np.random.randint(0,len(dvalid),1)[0]    \n","#     input_ids = dvalid[select_idx].unsqueeze(0)\n","    noise = np.random.randint(1, 20, max_position_embeddings).reshape(1,-1)\n","    input_ids = torch.from_numpy(noise).to('cuda')\n","#     print(input_ids)\n","    \n","    for j in range(max_position_embeddings):\n","        tempval = 0\n","        tempval += input_ids[0, j].item()\n","        if tempval != 0:\n","            logits = model(input_ids)[0][0,j]\n","            soft = torch.exp(logits)\n","            softproportion = (soft[tempval]/torch.sum(soft)).item()\n","            softsum += softproportion\n","            maxsum += 1\n","\n","            pred = torch.argmax(logits).item()\n","            actual = tempval\n","            n_correct += pred==actual\n","            n_total +=1\n","            \n","\n","correctness = softsum/maxsum\n","print(correctness)\n","\n","correctness_p = n_correct/n_total\n","print(correctness_p)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.05541888910197303\n","0.057\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SWYhjgeVVjuj","colab_type":"code","outputId":"6b00ed4b-6774-4efd-c73f-cde2cead509f","executionInfo":{"status":"ok","timestamp":1572282581109,"user_tz":240,"elapsed":916,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# evaluate using model that just predicts most common amino acid\n","model.eval()\n","\n","np.random.seed(4242424)\n","\n","\n","maxsum = 0\n","softsum = 0\n","n_correct = 0\n","n_total = 0\n","for i in range(100):\n","    select_idx = np.random.randint(0,len(dvalid),1)[0]    \n","    input_ids = dvalid[select_idx].unsqueeze(0)\n","    \n","    for j in range(max_position_embeddings):\n","        tempval = 0\n","        tempval += input_ids[0, j].item()\n","        if tempval != 0:\n","            soft = torch.zeros(vocab_size)\n","            soft[1] += 1 ################\n","            softproportion = (soft[tempval]/torch.sum(soft)).item()\n","            softsum += softproportion\n","            maxsum += 1\n","\n","            pred = torch.argmax(soft).item()\n","\n","            actual = tempval\n","            n_correct += pred==actual\n","            n_total += 1\n","            \n","correctness = softsum/maxsum\n","print(correctness)\n","\n","correctness_p = n_correct/n_total\n","print(correctness_p)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.10075\n","0.10075\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M36vnpBJVjsu","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MC_TvK5RVjcA","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IY73upOVVjZu","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fH281QsnVjXH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g9O2DuEMHm3X","colab_type":"code","outputId":"33f7f727-46c2-4862-c0b8-3f54ae7afc50","executionInfo":{"status":"ok","timestamp":1571861136594,"user_tz":240,"elapsed":1767,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# evaluate model GPT2\n","model.eval()\n","\n","np.random.seed(424242)\n","\n","n_correct = 0\n","n_wrong = 0\n","for i in range(200):\n","    select_idx = np.random.randint(0,len(dvalid), 2)[0]    \n","    input_ids = dvalid[select_idx].unsqueeze(0)\n","    logits = model(input_ids, labels=input_ids)[1]\n","    prediction = torch.argmax(logits, 2)\n","#     print(logits.shape)\n","#     print(prediction)\n","#     print(input_ids)\n","    correct = torch.sum(prediction[0, 1:]==input_ids[0, 1:]).item()\n","    n_correct += correct # exclude first value because model is directionally causal\n","    n_wrong += (max_position_embeddings-1)-correct # max possible is max_position_embeddings-1\n","#     print(n_correct, n_wrong)\n","\n","print(n_correct/(n_correct+n_wrong))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.12\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A_oX0DI-LKew","colab_type":"code","outputId":"d11c0985-ff9f-47b5-c3c1-2f78f5aba3f5","executionInfo":{"status":"ok","timestamp":1571861141912,"user_tz":240,"elapsed":3760,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# evaluate model GPT2 ON NOISE, should be 0.05\n","model.eval()\n","\n","np.random.seed(42)\n","\n","n_correct = 0\n","n_wrong = 0\n","for i in range(1000):\n","    noise = np.random.randint(1, 20, max_position_embeddings).reshape(1,-1)\n","    input_ids = torch.from_numpy(noise).to('cuda')\n","    \n","    logits = model(input_ids, labels=input_ids)[1]\n","    prediction = torch.argmax(logits, 2)\n","#     print(prediction)\n","#     print(input_ids)\n","    correct = torch.sum(prediction[0, 1:]==input_ids[0, 1:]).item()\n","    n_correct += correct # exclude first value because model is directionally causal\n","    n_wrong += (max_position_embeddings-1)-correct # max possible score is max_position_embeddings-1\n","#     print(n_correct, n_wrong)\n","\n","print(n_correct/(n_correct+n_wrong))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.05333333333333334\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sHJLGmpjsOQo","colab_type":"code","outputId":"e7181a2b-b358-409a-b225-f89b41397d17","executionInfo":{"status":"ok","timestamp":1571859271202,"user_tz":240,"elapsed":1993,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# # evaluate model\n","# model.eval()\n","\n","# np.random.seed(424242)\n","# predseq = []\n","# actualseq = []\n","# for i in range(20):\n","#     select_idx = np.random.randint(0,len(dvalid),1)[0]    \n","#     input_ids = dvalid[select_idx].unsqueeze(0)\n","\n","    \n","# #     for j in range(max_position_embeddings):\n","#     for j in range(10):\n","\n","#         tempval = 0\n","#         tempval += input_ids[0, j].item()\n","#         if tempval != 0:\n","#             input_ids[0, j] = vocab_size-1 # mask label is the highest vocab number, never present in data\n","#             predicted_aa = torch.argmax(model(input_ids)[0][0,j]).item() # TODO mask padding 0's for attention\n","# #             print(model(input_ids)[0][0,j])\n","# #             print(input_ids)\n","# #             sys.exit()\n","#             input_ids[0,j] = tempval # set masked value back to original value\n","# #             print(model(input_ids)[0][0,j])\n","#             predseq.append(predicted_aa)\n","#             actualseq.append(tempval)\n","#             print(i, predicted_aa,tempval)\n","\n","# n_correct = 0\n","# n_wrong = 0\n","# for i, aa in enumerate(predseq):\n","#     if aa == actualseq[i]:\n","#         n_correct += 1\n","#     else:\n","#         n_wrong += 1\n","# print(n_correct/(n_correct+n_wrong))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0 11 10\n","0 9 20\n","0 4 9\n","0 4 7\n","0 1 1\n","0 12 7\n","0 4 7\n","0 8 1\n","0 6 1\n","0 12 1\n","1 11 10\n","1 9 18\n","1 4 1\n","1 11 19\n","1 1 12\n","1 12 7\n","1 4 9\n","1 8 19\n","1 6 11\n","1 12 3\n","2 11 11\n","2 8 6\n","2 4 14\n","2 11 13\n","2 1 14\n","2 12 10\n","2 4 9\n","2 8 6\n","2 6 8\n","2 12 19\n","3 11 14\n","3 8 10\n","3 4 2\n","3 11 1\n","3 1 13\n","3 12 8\n","3 4 9\n","3 8 19\n","3 6 11\n","3 12 19\n","4 11 19\n","4 8 5\n","4 4 15\n","4 4 17\n","4 1 5\n","4 12 16\n","4 4 7\n","4 8 19\n","4 6 6\n","4 12 4\n","5 11 8\n","5 8 2\n","5 4 9\n","5 11 3\n","5 1 2\n","5 12 7\n","5 4 5\n","5 8 17\n","5 6 6\n","5 12 1\n","6 11 20\n","6 8 8\n","6 4 7\n","6 11 4\n","6 1 1\n","6 12 18\n","6 4 14\n","6 8 2\n","6 6 6\n","6 12 3\n","7 11 18\n","7 8 6\n","7 4 9\n","7 4 10\n","7 1 4\n","7 12 2\n","7 4 11\n","7 8 14\n","7 6 6\n","7 12 7\n","8 11 6\n","8 9 15\n","8 4 10\n","8 4 1\n","8 1 6\n","8 12 6\n","8 4 3\n","8 8 2\n","8 6 4\n","8 12 3\n","9 11 10\n","9 9 1\n","9 4 10\n","9 11 9\n","9 1 10\n","9 12 17\n","9 4 16\n","9 8 8\n","9 6 6\n","9 12 10\n","10 11 19\n","10 8 17\n","10 4 3\n","10 4 14\n","10 1 9\n","10 12 2\n","10 4 2\n","10 8 14\n","10 6 9\n","10 12 18\n","11 11 19\n","11 8 6\n","11 4 15\n","11 4 3\n","11 1 6\n","11 12 6\n","11 4 17\n","11 8 6\n","11 6 6\n","11 12 14\n","12 11 6\n","12 9 8\n","12 4 16\n","12 4 1\n","12 1 19\n","12 12 13\n","12 4 3\n","12 8 8\n","12 6 6\n","12 12 16\n","13 11 1\n","13 8 18\n","13 4 17\n","13 11 14\n","13 1 1\n","13 12 14\n","13 4 10\n","13 8 1\n","13 6 2\n","13 12 14\n","14 11 15\n","14 8 1\n","14 4 6\n","14 4 7\n","14 1 4\n","14 12 2\n","14 4 15\n","14 8 7\n","14 6 19\n","14 12 11\n","15 11 6\n","15 9 20\n","15 4 6\n","15 4 2\n","15 1 2\n","15 12 19\n","15 12 1\n","15 8 19\n","15 6 2\n","15 12 12\n","16 11 15\n","16 8 18\n","16 4 2\n","16 11 10\n","16 1 11\n","16 12 9\n","16 4 10\n","16 8 12\n","16 6 6\n","16 12 14\n","17 11 10\n","17 9 18\n","17 4 6\n","17 4 19\n","17 1 8\n","17 12 6\n","17 4 17\n","17 8 1\n","17 6 9\n","17 12 19\n","18 11 5\n","18 9 1\n","18 4 19\n","18 4 10\n","18 1 6\n","18 12 15\n","18 4 6\n","18 8 8\n","18 6 11\n","18 12 11\n","19 11 19\n","19 8 6\n","19 4 10\n","19 4 15\n","19 1 1\n","19 12 2\n","19 4 7\n","19 8 7\n","19 6 1\n","19 12 8\n","0.09\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ofUqreTNAdS3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pNzBaw3IAdE7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qsYYknW6rZcs","colab_type":"code","colab":{}},"source":["    \n","    \n","    \n","\n","#     for j in range(max_position_embeddings):\n","#         tempval = torch.zeros(batch_size).long()\n","\n","#         for k in range(batch_size):\n","#             tempval[k] = input_ids[k, j].item()\n","        \n","#         optimizer.zero_grad()\n","\n","# #         loss_mask[:, j] = tempval # calculate loss based only on masked amino acid\n","      \n","# #         input_ids[:, j] = vocab_size-1 # mask label is the highest vocab number, never present in data\n","\n","#         outputs = model(input_ids, labels=) #TODO mask padding 0's for attention\n","# #         print(outputs)\n","\n","#         loss, prediction_scores = outputs[:2]\n","#         print(outputs.shape)\n","#         sys.exit()\n","# #         loss, prediction_scores = outputs\n","\n","        \n","#         for k in range(batch_size):\n","#             print(i, torch.argmax(prediction_scores[k,j]).item(), loss_mask[k,j].item(), \"\\t\", loss.item())\n","#         print()\n","        \n","#         loss.backward()\n","#         optimizer.step()\n","\n","#         for k in range(batch_size):\n","#             input_ids[k, j] = tempval[k] # set masked value back to original value\n","#             loss_mask[k, j] = -1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W7HkebPG55YS","colab_type":"code","colab":{}},"source":["# # train model with single aa masked at a time\n","# model.train()\n","# loss_mask = (torch.zeros(max_position_embeddings)-1).long().to('cuda')\n","\n","# np.random.seed(2019)\n","# for i in range(1000):\n","#     select_idx = np.random.randint(0,len(dtrain),1)[0]    \n","#     input_ids = dtrain[select_idx].unsqueeze(0)\n","\n","#     for j in range(max_position_embeddings):\n","#         tempval = 0\n","#         tempval += input_ids[0, j].item()\n","#         if tempval != 0:\n","#             optimizer.zero_grad()\n","\n","#             loss_mask[j] = tempval # calculate loss based only on masked amino acid\n","#             input_ids[0, j] = vocab_size-1 # mask label is the highest vocab number, never present in data\n","\n","#             outputs = model(input_ids, masked_lm_labels=loss_mask) #TODO mask padding 0's for attention\n","#             loss, prediction_scores = outputs[:2]\n","#             print(i, torch.argmax(prediction_scores[0,j]).item(), loss.item())\n","#             loss.backward()\n","#             optimizer.step()\n","\n","#             input_ids[0,j] = tempval # set masked value back to original value\n","#             loss_mask[j] = -1\n","\n","# #             if j==10:\n","# #                 break\n","#         else:\n","#             break # stop training at end of protein sequence\n","\n","# #     break"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PKPz_z3Z55YU","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4JIPb1Sk55YW","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DOrHuRH_55YY","colab_type":"code","outputId":"2c3668c5-7748-4179-80b2-0c68cf316f98","executionInfo":{"status":"ok","timestamp":1571847057385,"user_tz":240,"elapsed":343,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":[""],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([1, 100, 22])\n","1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z2RpZdto55Ya","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NRKlpDWC55Yb","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"19Smkiji55Yd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BtmrJyUJ55Ye","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QwRPG3cX55Yg","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oThB3Osi55Yi","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"laiAuExQ55Yn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r7xT6bIj55Yo","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IsWkzh0t55Yq","colab_type":"code","colab":{}},"source":["def evaluate(model, data):\n","    model.eval()\n","    acc_list = []\n","    for d in data:\n","        outputs = model(d.unsqueeze(0), masked_lm_labels=d.unsqueeze(0))\n","        loss, prediction_scores = outputs[:2]\n","        \n","        predicted_index = torch.argmax(prediction_scores, dim=2)\n","        n_correct = torch.sum(predicted_index==d).item()\n","#         n_possible = torch.sum(d!=0).item()\n","        n_possible = len(predicted_index[0])\n","        acc = n_correct/n_possible\n","        acc_list.append(acc)\n","        \n","    return(np.mean(acc_list))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-0tWGotR55Yy","colab_type":"code","colab":{}},"source":["# train model\n","batch_size = 1\n","\n","optimizer = optim.SGD(model.parameters(), lr=0.01)#, momentum=args.momentum)\n","# optimizer = optim.AdamW(model.parameters())\n","_max_select = len(dtrain)\n","\n","\n","# single step to non-zero weights\n","optimizer.zero_grad()\n","select_idx = np.random.randint(0, _max_select, batch_size)\n","outputs = model(dtrain[select_idx], masked_lm_labels=dtrain[select_idx])\n","loss, prediction_scores = outputs[:2]\n","loss.backward()\n","optimizer.step()\n","\n","# # evaluate before training\n","# acc_train = evaluate(model, dtrain)\n","# acc_valid = evaluate(model, dvalid)\n","# print(acc_train)\n","# print(acc_valid)\n","\n","\n","# train\n","model.train()\n","np.random.seed(2019)\n","for i in range(100):\n","    optimizer.zero_grad()\n","    select_idx = np.random.randint(0, _max_select, batch_size)\n","    input_ids = tokens_tensor[select_idx]\n","    outputs = model(input_ids, masked_lm_labels=input_ids)\n","    loss, prediction_scores = outputs[:2]\n","    print(i, loss.item())\n","    loss.backward()\n","    optimizer.step()\n","    \n","#     loss.backward(retain_graph=True)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EH1AQEIR55Y0","colab_type":"code","colab":{}},"source":["# after training\n","acc_train = evaluate(model, dtrain)\n","acc_valid = evaluate(model, dvalid)\n","print(acc_train)\n","print(acc_valid)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cFBbjL0U55Y2","colab_type":"code","colab":{}},"source":["model.eval()\n","outputs = model(dvalid[0].unsqueeze(0), masked_lm_labels=dvalid[0].unsqueeze(0))\n","loss, prediction_scores = outputs[:2]\n","\n","predicted_index = torch.argmax(prediction_scores, dim=2)\n","print(predicted_index)\n","print(dvalid[0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5-S5jD8b55Y3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MrUL2vPe55Y5","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UM8u0ry555Y6","colab_type":"code","colab":{}},"source":["\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tJJWFg6E55Y8","colab_type":"code","colab":{}},"source":["# debug\n","model.train()\n","optimizer = optim.SGD(model.parameters(), lr=0.01)#, momentum=args.momentum)\n","for i in range(10):\n","    optimizer.zero_grad()\n","#     select_idx = 1\n","#     input_ids = tokens_tensor[select_idx].unsqueeze(0)\n","#     input_ids = tokens_tensor[0:3]\n","    input_ids = dtrain[0].unsqueeze(0)\n","\n","    outputs = model(input_ids, masked_lm_labels=input_ids)\n","    loss, prediction_scores = outputs[:2]\n","    print(i, loss.item())\n","    loss.backward()\n","    optimizer.step()\n","    \n","#     loss.backward(retain_graph=True)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KRXZhMQl55Y-","colab_type":"code","colab":{}},"source":["model.eval()\n","select_idx = 5\n","input_ids = tokens_tensor[select_idx].unsqueeze(0)\n","outputs = model(input_ids, masked_lm_labels=input_ids)\n","loss, prediction_scores = outputs[:2]\n","\n","predicted_index = torch.argmax(prediction_scores, dim=2)\n","a = evaluate(model, tokens_tensor[select_idx].unsqueeze(0))\n","print(a)\n","# print(predicted_index.shape)\n","print(predicted_index)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rPNcl53N55ZA","colab_type":"code","colab":{}},"source":["# evaluate on random data to ensure accuracy metric works\n","model.eval()\n","\n","np.random.seed(2019)\n","noise = np.random.randint(1, 10, 512).reshape(1,-1)\n","input_ids = torch.from_numpy(noise).to('cuda')\n","\n","outputs = model(input_ids, masked_lm_labels=input_ids)\n","loss, prediction_scores = outputs[:2]\n","\n","predicted_index = torch.argmax(prediction_scores, dim=2)\n","a = evaluate(model, tokens_tensor[select_idx].unsqueeze(0))\n","print(a)\n","# print(predicted_index.shape)\n","print(input_ids)\n","print(predicted_index)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Vnu2wrN55ZC","colab_type":"code","colab":{}},"source":["# fix forward mask\n","model.eval()\n","\n","np.random.seed(2019)\n","noise = np.random.randint(1, 10, 512).reshape(1,-1)\n","input_ids = torch.from_numpy(noise).to('cuda')\n","input_ids[0,0] = -inf\n","\n","attention_mask = torch.from_numpy(np.ones(512).reshape(1,-1)).float().to('cuda')\n","attention_mask[0,0] = 0\n","# print(attention_mask)\n","\n","token_type_ids = torch.from_numpy(np.zeros(512).reshape(1,-1)).long().to('cuda')\n","\n","outputs = model(input_ids, masked_lm_labels=input_ids)\n","loss, prediction_scores = outputs[:2]\n","\n","predicted_index = torch.argmax(prediction_scores, dim=2)\n","a = evaluate(model, tokens_tensor[select_idx].unsqueeze(0))\n","print(a)\n","# print(predicted_index.shape)\n","print(input_ids)\n","print(predicted_index)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pJau2_9b55ZE","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XT2JkPMN55ZG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6j2KIu7f55ZI","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7Z0_Jgm55ZK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ASXO5gOa55ZN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PSU4rrdO55ZP","colab_type":"code","colab":{}},"source":["del model\n","torch.cuda.empty_cache()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aI-t2Rs555ZU","colab_type":"code","colab":{}},"source":["# train model\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","def train_epoch(epoch, args, model, device, data_loader, optimizer):\n","    model.train()  # set to training mode, disappointingly does not actually train the model \n","    pid = os.getpid()\n","    for batch_idx, (data, target) in enumerate(data_loader):\n","        optimizer.zero_grad()\n","        output = model(data.to(device))\n","        loss = F.nll_loss(output, target.to(device))\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % args.log_interval == 0:\n","            print('{}\\tTrain Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                pid, epoch, batch_idx * len(data), len(data_loader.dataset),\n","                100. * batch_idx / len(data_loader), loss.item()))\n","            \n","optimizer = optim.SGD(model.parameters(), lr=0.01)#, momentum=args.momentum)\n","optimizer.zero_grad()\n","# output = model(tokens_tensor)\n","# loss = F.nll_loss(output, target.to('cuda'))\n","print([x for x in model.parameters()])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PoBBBQeO55ZV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iiY2TVZI55ZW","colab_type":"code","colab":{}},"source":["from transformers import BertTokenizer, BertModel, BertForMaskedLM\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","# model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n","model = BertForMaskedLM(config)\n","\n","input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\")).unsqueeze(0)  # Batch size 1\n","outputs = model(input_ids, masked_lm_labels=input_ids)\n","loss, prediction_scores = outputs[:2]\n","print(loss)\n","print(prediction_scores)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gxSiqrMs55ZY","colab_type":"code","colab":{}},"source":["print(input_ids.shape)\n","print(tokens_tensor[0].unsqueeze(0).shape)\n","print(tokens_tensor[0:2].shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DYID7shz55ZZ","colab_type":"code","colab":{}},"source":["from transformers import BertTokenizer, BertModel, BertForMaskedLM\n","\n","# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","# model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n","model = BertForMaskedLM(config)\n","model.to('cuda')\n","\n","# input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\")).unsqueeze(0)  # Batch size 1\n","# input_ids = tokens_tensor[0].unsqueeze(0)\n","input_ids = tokens_tensor[0:2]\n","\n","outputs = model(input_ids, masked_lm_labels=input_ids)\n","loss, prediction_scores = outputs[:2]\n","print(loss)\n","print(prediction_scores.shape)\n","\n","for i in range(2):\n","    input_ids = tokens_tensor[0:2]\n","    outputs = model(input_ids, masked_lm_labels=input_ids)\n","    loss, prediction_scores = outputs[:2]\n","    loss.backward()\n","    print(loss)\n","    print(prediction_scores.shape)\n","#     loss.backward(retain_graph=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XfFqO-6r55Zd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tGFpnqCO55Zh","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EXV_Oiij55Zi","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qpPPk-sf55Zl","colab_type":"code","colab":{}},"source":["import torch\n","from transformers import BertTokenizer, BertModel, BertForMaskedLM\n","\n","# OPTIONAL: if you want to have more information on what's happening under the hood, activate the logger as follows\n","# import logging\n","# logging.basicConfig(level=logging.INFO)\n","# logging.basicConfig(level=logging.NONE)\n","\n","\n","# Load pre-trained model tokenizer (vocabulary)\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# Tokenize input\n","text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n","tokenized_text = tokenizer.tokenize(text)\n","\n","# Mask a token that we will try to predict back with `BertForMaskedLM`\n","# masked_index = 8\n","# tokenized_text[masked_index] = '[MASK]'\n","\n","# Convert token to vocabulary indices\n","indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n","print(indexed_tokens)\n","# Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n","segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n","\n","# Convert inputs to PyTorch tensors\n","tokens_tensor = torch.tensor([indexed_tokens])\n","segments_tensors = torch.tensor([segments_ids])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"evUYO0la55Zn","colab_type":"code","colab":{}},"source":["# Load pre-trained model (weights)\n","model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n","model.eval()\n","\n","# If you have a GPU, put everything on cuda\n","tokens_tensor = tokens_tensor.to('cuda')\n","# segments_tensors = segments_tensors.to('cuda')\n","model.to('cuda')\n","\n","# Predict all tokens\n","with torch.no_grad():\n","#     outputs = model(tokens_tensor, token_type_ids=segments_tensors)\n","    outputs = model(tokens_tensor)\n","\n","    predictions = outputs[0]\n","\n","# confirm we were able to predict 'henson'\n","predicted_index = torch.argmax(predictions[0, masked_index]).item()\n","predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n","print(predicted_token)\n","\n","predicted_index = torch.argmax(predictions[0, 11]).item()\n","predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n","print(predicted_token)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PX9CA45w55Zq","colab_type":"code","colab":{}},"source":["for i in range(len(indexed_tokens)):\n","    predicted_index = torch.argmax(predictions[0, i]).item()\n","    predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n","    print(predicted_token)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MQ04k5P255Zr","colab_type":"code","colab":{}},"source":["predicted_token = tokenizer.convert_ids_to_tokens([103])[0]\n","print(predicted_token)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tThRe7ba55Zt","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gz4USnvY55Zv","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wz46wnbx55Zw","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KrqNGCF_55Zx","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tUsU5Ge655Zz","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dDVX4TcF55Z0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5L_l4eMA55Z1","colab_type":"code","colab":{}},"source":["import logging\n","logging.basicConfig(level=logging.INFO)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mH73ih9855Z2","colab_type":"code","colab":{}},"source":["# example tokenization\n","from transformers import BertTokenizer, BertModel, BertForMaskedLM\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n","tokenized_text = tokenizer.tokenize(text)\n","print(tokenized_text)\n","\n","masked_index = 8\n","tokenized_text[masked_index] = '[MASK]'\n","print(tokenized_text)\n","\n","indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n","tokens_tensor = torch.tensor([indexed_tokens])\n","print(tokens_tensor)\n","print(tokens_tensor.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YITbbsNm55Z3","colab_type":"code","colab":{}},"source":["# Load pre-trained model (weights)\n","model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n","model.eval()\n","\n","# If you have a GPU, put everything on cuda\n","tokens_tensor = tokens_tensor.to('cuda')\n","# segments_tensors = segments_tensors.to('cuda')\n","model.to('cuda')\n","\n","# Predict all tokens\n","with torch.no_grad():\n","#     outputs = model(tokens_tensor, token_type_ids=segments_tensors)\n","    outputs = model(tokens_tensor)\n","    predictions = outputs[0]\n","\n","# confirm we were able to predict 'henson'\n","predicted_index = torch.argmax(predictions[0, masked_index]).item()\n","predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n","print(predicted_token)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fd21GWBz55Z6","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ezPuox855Z8","colab_type":"code","outputId":"fab38698-1d71-45cb-ec06-f869068dd13b","executionInfo":{"status":"ok","timestamp":1571673957351,"user_tz":240,"elapsed":283731,"user":{"displayName":"Markus Sommer","photoUrl":"","userId":"08083804319459268544"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# GPT-2\n","\n","import torch\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","\n","# Load pre-trained model tokenizer (vocabulary)\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2-large')\n","\n","# Load pre-trained model (weights)\n","model = GPT2LMHeadModel.from_pretrained('gpt2-large')\n","\n","\n","# Set the model in evaluation mode to deactivate the DropOut modules\n","# This is IMPORTANT to have reproducible results during evaluation!\n","model.eval()\n","model.to('cuda')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 1042301/1042301 [00:01<00:00, 937069.71B/s]\n","100%|██████████| 456318/456318 [00:00<00:00, 500226.97B/s]\n","100%|██████████| 529/529 [00:00<00:00, 227614.57B/s]\n","100%|██████████| 3247202234/3247202234 [03:41<00:00, 14645396.05B/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(50257, 1280)\n","    (wpe): Embedding(1024, 1280)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (12): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (13): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (14): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (15): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (16): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (17): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (18): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (19): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (20): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (21): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (22): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (23): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (24): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (25): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (26): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (27): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (28): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (29): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (30): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (31): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (32): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (33): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (34): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (35): Block(\n","        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=1280, out_features=50257, bias=False)\n",")"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"Fj4V8Z8255Z_","colab_type":"code","colab":{}},"source":["# original_text = \"Martin Steinegger is in Peru because he \"\n","# original_text = \"The real reason Steven keeps recruiting German postdocs is \"\n","# original_text = \"The secret to giving a fun and compelling Joint Lab Meeting presentation is \"\n","# original_text = \"UC Berkeley is\"\n","# original_text = \"Why did Donald Trump \"\n","# original_text = \"Finding genes is easy... The secret is \"\n","# original_text = \"Computational gene finding is easy, the problem is \"\n","# original_text = \"The future of Biomedical Engineering is \"\n","# original_text = \"The best way to describe how neural networks work is \"\n","original_text = \"Improving on state-of-the-art bacterial gene finding programs is hard, \"\n","\n","\n","text = original_text\n","for i in range(20): # not the best way to iterate, but it works\n","    if text[-1] != \".\":\n","        # Encode a text inputs\n","        indexed_tokens = tokenizer.encode(text)\n","\n","        # Convert indexed tokens in a PyTorch tensor\n","        tokens_tensor = torch.tensor([indexed_tokens])\n","\n","        # If you have a GPU, put everything on cuda\n","        tokens_tensor = tokens_tensor.to('cuda')\n","\n","        # Predict all tokens\n","        with torch.no_grad():\n","            outputs = model(tokens_tensor)\n","            predictions = outputs[0]\n","\n","        # get the predicted next sub-word (in our case, the word 'man')\n","        predicted_index = torch.argmax(predictions[0, -1, :]).item()\n","        predicted_text = tokenizer.decode(indexed_tokens + [predicted_index])\n","\n","        text = predicted_text"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GnlswbS155aA","colab_type":"code","outputId":"7ed70e38-64f6-4c01-861d-013d549c29bf","colab":{}},"source":["print(\"Original text:\\t\\t\", original_text)\n","print(\"Completed sentence:\\t\", predicted_text)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Original text:\t\t Improving on state-of-the-art bacterial gene finding programs is hard, \n","Completed sentence:\t Improving on state-of-the-art bacterial gene finding programs is hard, but it's not impossible.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AT2RmpXZ55aC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FFR-o-dr55aD","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KKSSFryL55aE","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aqxg6dGV55aF","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aUvkNFcZ55aH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vn9QworP55aI","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7br8_zL55aL","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0t_F1Fno55aL","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ru6wfCmi55aN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}